{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DistilBERT_Ironys.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8590dd6949f5435dba2d369419ce1566":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3f671ae97df64b14996e8939af43cc90","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d04fc9440bed4ccebdc5eefc2ea2113f","IPY_MODEL_f6251ba09dba4c77b434ba1667c7160f"]}},"3f671ae97df64b14996e8939af43cc90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d04fc9440bed4ccebdc5eefc2ea2113f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6b8b56520ee04ddb97eb1e005a5b27f5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e39eb2abaa0407e9e16f1b2286da1b8"}},"f6251ba09dba4c77b434ba1667c7160f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_63a8073564314e8fa0553d80528b582c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:02&lt;00:00, 88.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6abf0925c0849e79d4a56c7a20a628f"}},"6b8b56520ee04ddb97eb1e005a5b27f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3e39eb2abaa0407e9e16f1b2286da1b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63a8073564314e8fa0553d80528b582c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c6abf0925c0849e79d4a56c7a20a628f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7376f1b433b4c2581e49009516b468c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_75dc7cf3331f43869114401871fbbe43","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cab70cd281a545d0a03005aaaa9b84ed","IPY_MODEL_899cceff1d4b48b08ca0db8e397483f4"]}},"75dc7cf3331f43869114401871fbbe43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cab70cd281a545d0a03005aaaa9b84ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_46128a159b744de294dcd7cddd31cb17","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30190ef775124b15970ff0cd84b40d3e"}},"899cceff1d4b48b08ca0db8e397483f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9fd4a316d70d492fa954c55989a7adb3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:01&lt;00:00, 28.6B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0c5b2daaa6249c7b7584fcd39b3f428"}},"46128a159b744de294dcd7cddd31cb17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30190ef775124b15970ff0cd84b40d3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fd4a316d70d492fa954c55989a7adb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c0c5b2daaa6249c7b7584fcd39b3f428":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a15edf60f1e4e43b6f7a41ba5ebcc3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ca182370f26e4998b4972da8483a877b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_83c833e6eb784bddab666f7a9c6e26c6","IPY_MODEL_58b127382d974633b44320cd5006bc9e"]}},"ca182370f26e4998b4972da8483a877b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83c833e6eb784bddab666f7a9c6e26c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c8fdc48698734f858052a0bdab32c445","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c089404dd7dc4a5f993c0832b5b6a009"}},"58b127382d974633b44320cd5006bc9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f0377651707d4772b0f2c434516d1abc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436k/436k [00:00&lt;00:00, 987kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20c40b890e84499686df19a0bb8fea83"}},"c8fdc48698734f858052a0bdab32c445":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c089404dd7dc4a5f993c0832b5b6a009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0377651707d4772b0f2c434516d1abc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20c40b890e84499686df19a0bb8fea83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c67c6efb14414ccc9ee3d4fc5a40ae5b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3adbe869c4cd45808845d5197331079a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_01bee90add954fa9a2bd53f66b8aa9dd","IPY_MODEL_006947d30fb4402b9bd3b449670eaba2"]}},"3adbe869c4cd45808845d5197331079a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01bee90add954fa9a2bd53f66b8aa9dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a88785d8c0cd4ae2af9aeae0ac4ba331","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":442,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":442,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5c48a105c6de4351a683d9346a0517cc"}},"006947d30fb4402b9bd3b449670eaba2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aa99d1553b594b2ba456d46dac150435","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 442/442 [00:00&lt;00:00, 1.16kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e95cb33a7ee749248b26e843a18d51b5"}},"a88785d8c0cd4ae2af9aeae0ac4ba331":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5c48a105c6de4351a683d9346a0517cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa99d1553b594b2ba456d46dac150435":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e95cb33a7ee749248b26e843a18d51b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca19fab2671e4443a38324dd722be2d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7b59e2bf0dc04492a4b4740e473bf6de","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f205a14efd048799556695ebac0a80d","IPY_MODEL_b41712e39de64bd68f7580124ec69336"]}},"7b59e2bf0dc04492a4b4740e473bf6de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f205a14efd048799556695ebac0a80d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_646885d37d0d4ec0b24f387f38bb6be5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":267967963,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267967963,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b31c661a8fe649afb7a1e71862c66e42"}},"b41712e39de64bd68f7580124ec69336":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d8143552bcc4384882bf4b21e27848b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 268M/268M [13:12&lt;00:00, 338kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0e8dbbee403547209aa3a75296dc6f8e"}},"646885d37d0d4ec0b24f387f38bb6be5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b31c661a8fe649afb7a1e71862c66e42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d8143552bcc4384882bf4b21e27848b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0e8dbbee403547209aa3a75296dc6f8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ksV9wOQQPXUS","executionInfo":{"status":"ok","timestamp":1618307079845,"user_tz":-120,"elapsed":17026,"user":{"displayName":"Tianyu Mo","photoUrl":"","userId":"10231734080128882793"}},"outputId":"d12d4939-2a40-4fc9-e2ee-44446b82c965"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bVnEoR9SNET9"},"source":["# 1. Importing Python Libraries and preparing the environment\n","At this step we will be importing the libraries and modules needed to run our script. Libraries are:"]},{"cell_type":"code","metadata":{"id":"CU9PW9TEM3Ad","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618307089576,"user_tz":-120,"elapsed":26749,"user":{"displayName":"Tianyu Mo","photoUrl":"","userId":"10231734080128882793"}},"outputId":"bc00880e-2415-4567-b9ae-119cb37a310e"},"source":["import numpy as np\n","from sklearn import metrics\n","import pandas as pd\n","import torch\n","! pip install transformers\n","import transformers\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import DistilBertModel, DistilBertTokenizer\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n","\r\u001b[K     |▏                               | 10kB 27.2MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 32.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 21.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 17.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 15.1MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 14.4MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 14.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 92kB 14.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 13.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 112kB 13.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 122kB 13.8MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 13.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 143kB 13.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 153kB 13.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 163kB 13.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 174kB 13.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 184kB 13.8MB/s eta 0:00:01\r\u001b[K     |███                             | 194kB 13.8MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 13.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 215kB 13.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 225kB 13.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 235kB 13.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 245kB 13.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 256kB 13.8MB/s eta 0:00:01\r\u001b[K     |████                            | 266kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 276kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 286kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 296kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 307kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 317kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 327kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 337kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 348kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 358kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 368kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 378kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 389kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 399kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 409kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 419kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 430kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 440kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 450kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 460kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 471kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 481kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 491kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 501kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 512kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 522kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 532kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 542kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 552kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 563kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 573kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 583kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 593kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 604kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 614kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 624kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 634kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 645kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 655kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 665kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 675kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 686kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 696kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 706kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 716kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 727kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 737kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 747kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 757kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 768kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 778kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 788kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 798kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 808kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 819kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 829kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 839kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 849kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 860kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 870kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 880kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 890kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 901kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 911kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 921kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 931kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 942kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 952kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 962kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 972kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 983kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 993kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.2MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.3MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.4MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.5MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.6MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.7MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.8MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.9MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.0MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.1MB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.2MB 13.8MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 36.4MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n","\u001b[K     |████████████████████████████████| 870kB 62.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=1607421f461697fb986dbd06a71eed8aade60daafbcce08ef3857473a18f142f\n","  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xPtoFlSDNOHT"},"source":["Set cuda device"]},{"cell_type":"code","metadata":{"id":"a5L3XCBwNPgN"},"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GLJ_EXDnOT3-"},"source":["# 2. Prepare the dataset and dataloader, using DistilBERT tokenization"]},{"cell_type":"code","metadata":{"id":"CDJ1f_ZzOa0p"},"source":["# train set dataframe\n","train_df = pd.read_csv(\"preprocessd_train.csv\", index_col=None)\n","\n","# test set dataframe\n","test_df = pd.read_csv(\"preprocessd_test.csv\", index_col=None)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NMaB6jxTbX7","colab":{"base_uri":"https://localhost:8080/","height":166,"referenced_widgets":["8590dd6949f5435dba2d369419ce1566","3f671ae97df64b14996e8939af43cc90","d04fc9440bed4ccebdc5eefc2ea2113f","f6251ba09dba4c77b434ba1667c7160f","6b8b56520ee04ddb97eb1e005a5b27f5","3e39eb2abaa0407e9e16f1b2286da1b8","63a8073564314e8fa0553d80528b582c","c6abf0925c0849e79d4a56c7a20a628f","a7376f1b433b4c2581e49009516b468c","75dc7cf3331f43869114401871fbbe43","cab70cd281a545d0a03005aaaa9b84ed","899cceff1d4b48b08ca0db8e397483f4","46128a159b744de294dcd7cddd31cb17","30190ef775124b15970ff0cd84b40d3e","9fd4a316d70d492fa954c55989a7adb3","c0c5b2daaa6249c7b7584fcd39b3f428","4a15edf60f1e4e43b6f7a41ba5ebcc3a","ca182370f26e4998b4972da8483a877b","83c833e6eb784bddab666f7a9c6e26c6","58b127382d974633b44320cd5006bc9e","c8fdc48698734f858052a0bdab32c445","c089404dd7dc4a5f993c0832b5b6a009","f0377651707d4772b0f2c434516d1abc","20c40b890e84499686df19a0bb8fea83"]},"executionInfo":{"status":"ok","timestamp":1618307095287,"user_tz":-120,"elapsed":32446,"user":{"displayName":"Tianyu Mo","photoUrl":"","userId":"10231734080128882793"}},"outputId":"e3e6d7df-1b5a-403a-c856-fcf345964549"},"source":["# Defining some key variables that will be used later on in the training\n","MAX_LEN = 512\n","TRAIN_BATCH_SIZE = 16\n","EPOCHS = 50\n","LEARNING_RATE = 1e-05\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8590dd6949f5435dba2d369419ce1566","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7376f1b433b4c2581e49009516b468c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a15edf60f1e4e43b6f7a41ba5ebcc3a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nIRh6brgjLW6"},"source":["test_label = test_df[\"label\"]\n","true_labels = np.array(test_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKNa1dsSTifC"},"source":["class Preprocess(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        text = str(self.data.text[index])        \n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': torch.tensor(self.data.label[index], dtype=torch.long)\n","        } \n","    \n","    def __len__(self):\n","        return self.len"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qS9ftIIUht4"},"source":["# Creating the dataset and dataloader for the neural network\n","\n","training_set = Preprocess(train_df, tokenizer, MAX_LEN)\n","testing_set = Preprocess(test_df, tokenizer, MAX_LEN)\n","\n","train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3b_iKjkMVK1F"},"source":["# 3. Creat neural network with DistilBERT for fine tuning"]},{"cell_type":"code","metadata":{"id":"kp4eoQLNVRus"},"source":["# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n","\n","class DistillBERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(DistillBERTClass, self).__init__()\n","        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, 2)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c67c6efb14414ccc9ee3d4fc5a40ae5b","3adbe869c4cd45808845d5197331079a","01bee90add954fa9a2bd53f66b8aa9dd","006947d30fb4402b9bd3b449670eaba2","a88785d8c0cd4ae2af9aeae0ac4ba331","5c48a105c6de4351a683d9346a0517cc","aa99d1553b594b2ba456d46dac150435","e95cb33a7ee749248b26e843a18d51b5","ca19fab2671e4443a38324dd722be2d4","7b59e2bf0dc04492a4b4740e473bf6de","9f205a14efd048799556695ebac0a80d","b41712e39de64bd68f7580124ec69336","646885d37d0d4ec0b24f387f38bb6be5","b31c661a8fe649afb7a1e71862c66e42","0d8143552bcc4384882bf4b21e27848b","0e8dbbee403547209aa3a75296dc6f8e"]},"id":"H5lrGXtbVcXv","executionInfo":{"status":"ok","timestamp":1618307107957,"user_tz":-120,"elapsed":45087,"user":{"displayName":"Tianyu Mo","photoUrl":"","userId":"10231734080128882793"}},"outputId":"80f1e038-b28b-4ef2-fe09-7e7bb35c4845"},"source":["model = DistillBERTClass()\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c67c6efb14414ccc9ee3d4fc5a40ae5b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca19fab2671e4443a38324dd722be2d4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["DistillBERTClass(\n","  (l1): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"ViqZHmTcVeSA"},"source":["# Creating the loss function and optimizer\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uj7WP0LgVs_W"},"source":["# 4. Train the model"]},{"cell_type":"code","metadata":{"id":"T2guxzY1Vux3"},"source":["# Function to calcuate the accuracy of the model\n","\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vEHbvasAY8NR"},"source":["train_losses = []\n","train_accs = []\n","test_losses = []\n","test_accs = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EdxS27V9Vz7D"},"source":["def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _,data in enumerate(training_loader, 0):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","\n","        outputs = model(ids, mask)\n","        loss = loss_function(outputs, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.data, dim=1)\n","        n_correct += calcuate_accu(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","        \n","        if _%5000==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            accu_step = (n_correct*100)/nb_tr_examples \n","            print(f\"Training Loss per 5000 steps: {loss_step}\")\n","            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # # When using GPU\n","        optimizer.step()\n","\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","    \n","    train_losses.append(epoch_loss)\n","    train_accs.append(epoch_accu)\n","\n","    return "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUiyQ5thWFYe"},"source":["\n","def test(model, testing_loader):\n","    model.eval()\n","    te_loss = 0; n_correct = 0; nb_te_steps = 0; nb_te_examples = 0; n_wrong = 0; total = 0\n","\n","    pred_labels = []\n","\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.long)\n","            outputs = model(ids, mask).squeeze()\n","            loss = loss_function(outputs, targets)\n","            te_loss += loss.item()\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calcuate_accu(big_idx, targets)\n","\n","            pred_labels.append(big_idx) \n","\n","            nb_te_steps += 1\n","            nb_te_examples+=targets.size(0)\n","            \n","            if _%5000==0:\n","                loss_step = te_loss/nb_te_steps\n","                accu_step = (n_correct*100)/nb_te_examples\n","                print(f\"Validation Loss per 100 steps: {loss_step}\")\n","                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","    epoch_loss = te_loss/nb_te_steps\n","    epoch_accu = (n_correct*100)/nb_te_examples\n","\n","    test_losses.append(epoch_loss)\n","    test_accs.append(epoch_accu)\n","\n","    print(f\"Validation Loss Epoch: {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","    \n","    \n","    \n","    \n","    return epoch_accu, pred_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41I6cZxeV4s8","executionInfo":{"status":"ok","timestamp":1618312724064,"user_tz":-120,"elapsed":5661157,"user":{"displayName":"Tianyu Mo","photoUrl":"","userId":"10231734080128882793"}},"outputId":"ffe3c9af-81d1-42c2-910b-c64d1771cdfb"},"source":["for epoch in tqdm(range(EPOCHS)):\n","    train(epoch)\n","    acc, pred_labels = test(model, testing_loader)\n","    print(\"Accuracy on test data = %0.2f%%\" % acc)  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 5000 steps: 0.6617779731750488\n","Training Accuracy per 5000 steps: 62.5\n","The Total Accuracy for Epoch 0: 57.094418362023994\n","Training Loss Epoch: 0.6737189826865991\n","Training Accuracy Epoch: 57.094418362023994\n","Validation Loss per 100 steps: 0.6642333269119263\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r  2%|▏         | 1/50 [01:52<1:31:41, 112.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577]\n","test_accs:  [61.224489795918366]\n","Validation Loss Epoch: 0.6400099165585577\n","Validation Accuracy Epoch: 61.224489795918366\n","Accuracy on test data = 61.22%\n","Training Loss per 5000 steps: 0.691350519657135\n","Training Accuracy per 5000 steps: 50.0\n","The Total Accuracy for Epoch 1: 63.171622326551905\n","Training Loss Epoch: 0.6360488350192706\n","Training Accuracy Epoch: 63.171622326551905\n","Validation Loss per 100 steps: 0.6515775322914124\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r  4%|▍         | 2/50 [03:44<1:29:46, 112.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021]\n","test_accs:  [61.224489795918366, 65.43367346938776]\n","Validation Loss Epoch: 0.6569189593500021\n","Validation Accuracy Epoch: 65.43367346938776\n","Accuracy on test data = 65.43%\n","Training Loss per 5000 steps: 0.5860155820846558\n","Training Accuracy per 5000 steps: 75.0\n","The Total Accuracy for Epoch 2: 67.8925404277517\n","Training Loss Epoch: 0.5958925771216551\n","Training Accuracy Epoch: 67.8925404277517\n","Validation Loss per 100 steps: 0.5930847525596619\n","Validation Accuracy per 100 steps: 75.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r  6%|▌         | 3/50 [05:36<1:27:54, 112.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347]\n","Validation Loss Epoch: 0.6093497683807295\n","Validation Accuracy Epoch: 67.7295918367347\n","Accuracy on test data = 67.73%\n","Training Loss per 5000 steps: 0.6716392040252686\n","Training Accuracy per 5000 steps: 62.5\n","The Total Accuracy for Epoch 3: 73.03077725612937\n","Training Loss Epoch: 0.5413685818513234\n","Training Accuracy Epoch: 73.03077725612937\n","Validation Loss per 100 steps: 0.6540905237197876\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r  8%|▊         | 4/50 [07:28<1:26:01, 112.21s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347]\n","Validation Loss Epoch: 0.6128950240660687\n","Validation Accuracy Epoch: 67.7295918367347\n","Accuracy on test data = 67.73%\n","Training Loss per 5000 steps: 0.3231419026851654\n","Training Accuracy per 5000 steps: 93.75\n","The Total Accuracy for Epoch 4: 79.39488784559207\n","Training Loss Epoch: 0.44973238992194337\n","Training Accuracy Epoch: 79.39488784559207\n","Validation Loss per 100 steps: 0.6168739795684814\n","Validation Accuracy per 100 steps: 68.75\n"],"name":"stdout"},{"output_type":"stream","text":["\r 10%|█         | 5/50 [09:21<1:24:09, 112.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654]\n","Validation Loss Epoch: 0.6521694337835118\n","Validation Accuracy Epoch: 67.60204081632654\n","Accuracy on test data = 67.60%\n","Training Loss per 5000 steps: 0.26785075664520264\n","Training Accuracy per 5000 steps: 87.5\n","The Total Accuracy for Epoch 5: 84.7678664580073\n","Training Loss Epoch: 0.3495716627376775\n","Training Accuracy Epoch: 84.7678664580073\n","Validation Loss per 100 steps: 1.1587523221969604\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 12%|█▏        | 6/50 [11:13<1:22:17, 112.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976]\n","Validation Loss Epoch: 0.8647014705502257\n","Validation Accuracy Epoch: 63.265306122448976\n","Accuracy on test data = 63.27%\n","Training Loss per 5000 steps: 0.13366135954856873\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 6: 90.16692749087115\n","Training Loss Epoch: 0.2579417894439151\n","Training Accuracy Epoch: 90.16692749087115\n","Validation Loss per 100 steps: 1.3817052841186523\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 14%|█▍        | 7/50 [13:05<1:20:25, 112.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634]\n","Validation Loss Epoch: 0.900049084911541\n","Validation Accuracy Epoch: 63.775510204081634\n","Accuracy on test data = 63.78%\n","Training Loss per 5000 steps: 0.11838523298501968\n","Training Accuracy per 5000 steps: 93.75\n","The Total Accuracy for Epoch 7: 92.61867501304121\n","Training Loss Epoch: 0.19781684752864143\n","Training Accuracy Epoch: 92.61867501304121\n","Validation Loss per 100 steps: 1.5780463218688965\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 16%|█▌        | 8/50 [14:57<1:18:33, 112.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224]\n","Validation Loss Epoch: 0.9775705665958171\n","Validation Accuracy Epoch: 65.81632653061224\n","Accuracy on test data = 65.82%\n","Training Loss per 5000 steps: 0.07096592336893082\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 8: 94.75743348982786\n","Training Loss Epoch: 0.14547074832177412\n","Training Accuracy Epoch: 94.75743348982786\n","Validation Loss per 100 steps: 1.6926424503326416\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 18%|█▊        | 9/50 [16:49<1:16:41, 112.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081]\n","Validation Loss Epoch: 1.1360047824528752\n","Validation Accuracy Epoch: 63.13775510204081\n","Accuracy on test data = 63.14%\n","Training Loss per 5000 steps: 0.028800277039408684\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 9: 95.64423578508085\n","Training Loss Epoch: 0.1130963912505346\n","Training Accuracy Epoch: 95.64423578508085\n","Validation Loss per 100 steps: 2.4474093914031982\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 20%|██        | 10/50 [18:42<1:14:48, 112.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551]\n","Validation Loss Epoch: 1.481410299028669\n","Validation Accuracy Epoch: 62.11734693877551\n","Accuracy on test data = 62.12%\n","Training Loss per 5000 steps: 0.04464676231145859\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 10: 96.7396974439228\n","Training Loss Epoch: 0.0932395548229882\n","Training Accuracy Epoch: 96.7396974439228\n","Validation Loss per 100 steps: 2.511085271835327\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 22%|██▏       | 11/50 [20:34<1:12:56, 112.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675]\n","Validation Loss Epoch: 1.3088316613314104\n","Validation Accuracy Epoch: 62.244897959183675\n","Accuracy on test data = 62.24%\n","Training Loss per 5000 steps: 0.06688176840543747\n","Training Accuracy per 5000 steps: 93.75\n","The Total Accuracy for Epoch 11: 96.47887323943662\n","Training Loss Epoch: 0.09919765414282058\n","Training Accuracy Epoch: 96.47887323943662\n","Validation Loss per 100 steps: 1.947605013847351\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r 24%|██▍       | 12/50 [22:26<1:11:04, 112.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245]\n","Validation Loss Epoch: 1.3027345057652922\n","Validation Accuracy Epoch: 64.41326530612245\n","Accuracy on test data = 64.41%\n","Training Loss per 5000 steps: 0.10592026263475418\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 12: 97.70474700052165\n","Training Loss Epoch: 0.0661772297937811\n","Training Accuracy Epoch: 97.70474700052165\n","Validation Loss per 100 steps: 1.6172306537628174\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r 26%|██▌       | 13/50 [24:18<1:09:12, 112.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613]\n","Validation Loss Epoch: 1.3971443316157983\n","Validation Accuracy Epoch: 64.15816326530613\n","Accuracy on test data = 64.16%\n","Training Loss per 5000 steps: 0.015869420021772385\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 13: 98.04381846635368\n","Training Loss Epoch: 0.05152430921831789\n","Training Accuracy Epoch: 98.04381846635368\n","Validation Loss per 100 steps: 1.9433025121688843\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 28%|██▊       | 14/50 [26:11<1:07:20, 112.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146]\n","Validation Loss Epoch: 1.5097090796548494\n","Validation Accuracy Epoch: 63.392857142857146\n","Accuracy on test data = 63.39%\n","Training Loss per 5000 steps: 0.010419942438602448\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 14: 98.77412623891497\n","Training Loss Epoch: 0.042956021378631706\n","Training Accuracy Epoch: 98.77412623891497\n","Validation Loss per 100 steps: 2.1126708984375\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 30%|███       | 15/50 [28:03<1:05:28, 112.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062]\n","Validation Loss Epoch: 1.5920255269323076\n","Validation Accuracy Epoch: 64.54081632653062\n","Accuracy on test data = 64.54%\n","Training Loss per 5000 steps: 0.005425251554697752\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 15: 98.20031298904539\n","Training Loss Epoch: 0.051165487892285456\n","Training Accuracy Epoch: 98.20031298904539\n","Validation Loss per 100 steps: 1.4450230598449707\n","Validation Accuracy per 100 steps: 75.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 32%|███▏      | 16/50 [29:55<1:03:36, 112.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204]\n","Validation Loss Epoch: 1.4352193687643324\n","Validation Accuracy Epoch: 65.9438775510204\n","Accuracy on test data = 65.94%\n","Training Loss per 5000 steps: 0.15244245529174805\n","Training Accuracy per 5000 steps: 93.75\n","The Total Accuracy for Epoch 16: 98.93062076160668\n","Training Loss Epoch: 0.0319951381078378\n","Training Accuracy Epoch: 98.93062076160668\n","Validation Loss per 100 steps: 2.148841142654419\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r 34%|███▍      | 17/50 [31:47<1:01:43, 112.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551]\n","Validation Loss Epoch: 1.5899538142340524\n","Validation Accuracy Epoch: 64.9234693877551\n","Accuracy on test data = 64.92%\n","Training Loss per 5000 steps: 0.0038713542744517326\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 17: 98.93062076160668\n","Training Loss Epoch: 0.03222611177867899\n","Training Accuracy Epoch: 98.93062076160668\n","Validation Loss per 100 steps: 2.607468843460083\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 36%|███▌      | 18/50 [33:40<59:52, 112.25s/it]  "],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613]\n","Validation Loss Epoch: 1.7731321952780899\n","Validation Accuracy Epoch: 64.15816326530613\n","Accuracy on test data = 64.16%\n","Training Loss per 5000 steps: 0.004123971331864595\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 18: 98.85237350026082\n","Training Loss Epoch: 0.031896563065917385\n","Training Accuracy Epoch: 98.85237350026082\n","Validation Loss per 100 steps: 2.499364137649536\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 38%|███▊      | 19/50 [35:32<57:59, 112.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776]\n","Validation Loss Epoch: 1.6994966986228008\n","Validation Accuracy Epoch: 65.43367346938776\n","Accuracy on test data = 65.43%\n","Training Loss per 5000 steps: 0.06913234293460846\n","Training Accuracy per 5000 steps: 93.75\n","The Total Accuracy for Epoch 19: 98.0699008868023\n","Training Loss Epoch: 0.049866232869923505\n","Training Accuracy Epoch: 98.0699008868023\n","Validation Loss per 100 steps: 2.0922203063964844\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 40%|████      | 20/50 [37:24<56:09, 112.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673]\n","Validation Loss Epoch: 1.3728274578342632\n","Validation Accuracy Epoch: 66.19897959183673\n","Accuracy on test data = 66.20%\n","Training Loss per 5000 steps: 0.005295977462083101\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 20: 99.13928012519561\n","Training Loss Epoch: 0.024671761395196275\n","Training Accuracy Epoch: 99.13928012519561\n","Validation Loss per 100 steps: 3.208162307739258\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 42%|████▏     | 21/50 [39:17<54:16, 112.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898]\n","Validation Loss Epoch: 1.8255518893806302\n","Validation Accuracy Epoch: 63.9030612244898\n","Accuracy on test data = 63.90%\n","Training Loss per 5000 steps: 0.005659838672727346\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 21: 99.37402190923318\n","Training Loss Epoch: 0.017171466142705562\n","Training Accuracy Epoch: 99.37402190923318\n","Validation Loss per 100 steps: 2.562150239944458\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 44%|████▍     | 22/50 [41:09<52:23, 112.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062]\n","Validation Loss Epoch: 1.9168345806550007\n","Validation Accuracy Epoch: 64.54081632653062\n","Accuracy on test data = 64.54%\n","Training Loss per 5000 steps: 0.0010927764233201742\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 22: 99.00886802295253\n","Training Loss Epoch: 0.03055402832615073\n","Training Accuracy Epoch: 99.00886802295253\n","Validation Loss per 100 steps: 2.7543880939483643\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 46%|████▌     | 23/50 [43:01<50:31, 112.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265]\n","Validation Loss Epoch: 1.8039779237338476\n","Validation Accuracy Epoch: 63.01020408163265\n","Accuracy on test data = 63.01%\n","Training Loss per 5000 steps: 0.0024920180439949036\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 23: 99.53051643192488\n","Training Loss Epoch: 0.013422884516209403\n","Training Accuracy Epoch: 99.53051643192488\n","Validation Loss per 100 steps: 2.625174045562744\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r 48%|████▊     | 24/50 [44:53<48:38, 112.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898]\n","Validation Loss Epoch: 2.076651930809021\n","Validation Accuracy Epoch: 63.9030612244898\n","Accuracy on test data = 63.90%\n","Training Loss per 5000 steps: 0.003947723191231489\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 24: 99.42618675013041\n","Training Loss Epoch: 0.018729488950945474\n","Training Accuracy Epoch: 99.42618675013041\n","Validation Loss per 100 steps: 2.837705612182617\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 25/50 [46:46<46:46, 112.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327]\n","Validation Loss Epoch: 2.0030470283664004\n","Validation Accuracy Epoch: 65.05102040816327\n","Accuracy on test data = 65.05%\n","Training Loss per 5000 steps: 0.000962009304203093\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 25: 99.2436098069901\n","Training Loss Epoch: 0.020616928058249565\n","Training Accuracy Epoch: 99.2436098069901\n","Validation Loss per 100 steps: 3.030869960784912\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 52%|█████▏    | 26/50 [48:38<44:55, 112.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306]\n","Validation Loss Epoch: 1.8041236461425314\n","Validation Accuracy Epoch: 66.45408163265306\n","Accuracy on test data = 66.45%\n","Training Loss per 5000 steps: 0.0007552733877673745\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 26: 99.5565988523735\n","Training Loss Epoch: 0.015501997524309748\n","Training Accuracy Epoch: 99.5565988523735\n","Validation Loss per 100 steps: 2.3617632389068604\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r 54%|█████▍    | 27/50 [50:30<43:03, 112.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776]\n","Validation Loss Epoch: 1.818214540578881\n","Validation Accuracy Epoch: 65.43367346938776\n","Accuracy on test data = 65.43%\n","Training Loss per 5000 steps: 0.0051422202959656715\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 27: 99.58268127282211\n","Training Loss Epoch: 0.013520705286888793\n","Training Accuracy Epoch: 99.58268127282211\n","Validation Loss per 100 steps: 2.9092049598693848\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 56%|█████▌    | 28/50 [52:23<41:10, 112.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306]\n","Validation Loss Epoch: 1.8594834901848618\n","Validation Accuracy Epoch: 66.45408163265306\n","Accuracy on test data = 66.45%\n","Training Loss per 5000 steps: 0.0044957417994737625\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 28: 99.68701095461658\n","Training Loss Epoch: 0.011226184935488466\n","Training Accuracy Epoch: 99.68701095461658\n","Validation Loss per 100 steps: 3.554330348968506\n","Validation Accuracy per 100 steps: 43.75\n"],"name":"stdout"},{"output_type":"stream","text":["\r 58%|█████▊    | 29/50 [54:15<39:18, 112.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325]\n","Validation Loss Epoch: 2.1067855759542815\n","Validation Accuracy Epoch: 62.755102040816325\n","Accuracy on test data = 62.76%\n","Training Loss per 5000 steps: 0.019960906356573105\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 29: 99.34793948878456\n","Training Loss Epoch: 0.019695318832964402\n","Training Accuracy Epoch: 99.34793948878456\n","Validation Loss per 100 steps: 2.83736515045166\n","Validation Accuracy per 100 steps: 43.75\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|██████    | 30/50 [56:07<37:25, 112.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184]\n","Validation Loss Epoch: 2.052985585465723\n","Validation Accuracy Epoch: 62.37244897959184\n","Accuracy on test data = 62.37%\n","Training Loss per 5000 steps: 0.00046660262160003185\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 30: 99.5565988523735\n","Training Loss Epoch: 0.01553497792883718\n","Training Accuracy Epoch: 99.5565988523735\n","Validation Loss per 100 steps: 2.911423444747925\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 62%|██████▏   | 31/50 [57:59<35:33, 112.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327]\n","Validation Loss Epoch: 1.9276424159809036\n","Validation Accuracy Epoch: 65.05102040816327\n","Accuracy on test data = 65.05%\n","Training Loss per 5000 steps: 0.0003863644087687135\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 31: 98.82629107981221\n","Training Loss Epoch: 0.032036216165821925\n","Training Accuracy Epoch: 98.82629107981221\n","Validation Loss per 100 steps: 2.875767230987549\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 64%|██████▍   | 32/50 [59:52<33:41, 112.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551]\n","Validation Loss Epoch: 1.6524228642181473\n","Validation Accuracy Epoch: 64.9234693877551\n","Accuracy on test data = 64.92%\n","Training Loss per 5000 steps: 0.0066091581247746944\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 32: 99.53051643192488\n","Training Loss Epoch: 0.013981059432868885\n","Training Accuracy Epoch: 99.53051643192488\n","Validation Loss per 100 steps: 2.921902656555176\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 66%|██████▌   | 33/50 [1:01:44<31:49, 112.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919]\n","Validation Loss Epoch: 2.0161510024751936\n","Validation Accuracy Epoch: 61.86224489795919\n","Accuracy on test data = 61.86%\n","Training Loss per 5000 steps: 0.0012528877705335617\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 33: 99.50443401147626\n","Training Loss Epoch: 0.014304514017567271\n","Training Accuracy Epoch: 99.50443401147626\n","Validation Loss per 100 steps: 3.383608818054199\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 68%|██████▊   | 34/50 [1:03:36<29:57, 112.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551]\n","Validation Loss Epoch: 1.8548836136350826\n","Validation Accuracy Epoch: 64.9234693877551\n","Accuracy on test data = 64.92%\n","Training Loss per 5000 steps: 0.002627964597195387\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 34: 99.79134063641106\n","Training Loss Epoch: 0.007609245704285664\n","Training Accuracy Epoch: 99.79134063641106\n","Validation Loss per 100 steps: 3.7203078269958496\n","Validation Accuracy per 100 steps: 43.75\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|███████   | 35/50 [1:05:29<28:04, 112.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531]\n","Validation Loss Epoch: 1.985793490799106\n","Validation Accuracy Epoch: 63.52040816326531\n","Accuracy on test data = 63.52%\n","Training Loss per 5000 steps: 0.00332853221334517\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 35: 99.63484611371935\n","Training Loss Epoch: 0.010488424725675334\n","Training Accuracy Epoch: 99.63484611371935\n","Validation Loss per 100 steps: 3.0890884399414062\n","Validation Accuracy per 100 steps: 37.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r 72%|███████▏  | 36/50 [1:07:21<26:12, 112.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634]\n","Validation Loss Epoch: 2.0437252460693824\n","Validation Accuracy Epoch: 63.775510204081634\n","Accuracy on test data = 63.78%\n","Training Loss per 5000 steps: 0.0003085314529016614\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 36: 99.7130933750652\n","Training Loss Epoch: 0.008886203009145296\n","Training Accuracy Epoch: 99.7130933750652\n","Validation Loss per 100 steps: 3.478107213973999\n","Validation Accuracy per 100 steps: 43.75\n"],"name":"stdout"},{"output_type":"stream","text":["\r 74%|███████▍  | 37/50 [1:09:14<24:21, 112.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325]\n","Validation Loss Epoch: 2.3441052972053993\n","Validation Accuracy Epoch: 62.755102040816325\n","Accuracy on test data = 62.76%\n","Training Loss per 5000 steps: 0.0018391563789919019\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 37: 99.79134063641106\n","Training Loss Epoch: 0.00779022672947273\n","Training Accuracy Epoch: 99.79134063641106\n","Validation Loss per 100 steps: 3.295267343521118\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 76%|███████▌  | 38/50 [1:11:06<22:28, 112.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327]\n","Validation Loss Epoch: 2.1530330083808122\n","Validation Accuracy Epoch: 65.05102040816327\n","Accuracy on test data = 65.05%\n","Training Loss per 5000 steps: 0.0005638111615553498\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 38: 99.08711528429838\n","Training Loss Epoch: 0.027383749062209972\n","Training Accuracy Epoch: 99.08711528429838\n","Validation Loss per 100 steps: 2.593210458755493\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 78%|███████▊  | 39/50 [1:12:58<20:36, 112.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634]\n","Validation Loss Epoch: 1.8283405200559266\n","Validation Accuracy Epoch: 63.775510204081634\n","Accuracy on test data = 63.78%\n","Training Loss per 5000 steps: 0.0009546398068778217\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 39: 99.8435054773083\n","Training Loss Epoch: 0.007008412099154763\n","Training Accuracy Epoch: 99.8435054773083\n","Validation Loss per 100 steps: 2.3898849487304688\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 80%|████████  | 40/50 [1:14:51<18:43, 112.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551]\n","Validation Loss Epoch: 2.0263126334365533\n","Validation Accuracy Epoch: 64.9234693877551\n","Accuracy on test data = 64.92%\n","Training Loss per 5000 steps: 0.00041730247903615236\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 40: 99.68701095461658\n","Training Loss Epoch: 0.01163150499293503\n","Training Accuracy Epoch: 99.68701095461658\n","Validation Loss per 100 steps: 2.154970169067383\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r 82%|████████▏ | 41/50 [1:16:43<16:50, 112.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325]\n","Validation Loss Epoch: 2.0230234374805374\n","Validation Accuracy Epoch: 62.755102040816325\n","Accuracy on test data = 62.76%\n","Training Loss per 5000 steps: 0.0007833524723537266\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 41: 99.63484611371935\n","Training Loss Epoch: 0.011534709278627512\n","Training Accuracy Epoch: 99.63484611371935\n","Validation Loss per 100 steps: 2.8937864303588867\n","Validation Accuracy per 100 steps: 50.0\n"],"name":"stdout"},{"output_type":"stream","text":["\r 84%|████████▍ | 42/50 [1:18:35<14:58, 112.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327]\n","Validation Loss Epoch: 2.022567380447777\n","Validation Accuracy Epoch: 65.05102040816327\n","Accuracy on test data = 65.05%\n","Training Loss per 5000 steps: 0.0011998733971267939\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 42: 99.66092853416797\n","Training Loss Epoch: 0.015039949567259707\n","Training Accuracy Epoch: 99.66092853416797\n","Validation Loss per 100 steps: 2.981794834136963\n","Validation Accuracy per 100 steps: 43.75\n"],"name":"stdout"},{"output_type":"stream","text":["\r 86%|████████▌ | 43/50 [1:20:28<13:06, 112.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777, 2.250903172152383]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327, 61.734693877551024]\n","Validation Loss Epoch: 2.250903172152383\n","Validation Accuracy Epoch: 61.734693877551024\n","Accuracy on test data = 61.73%\n","Training Loss per 5000 steps: 0.13382591307163239\n","Training Accuracy per 5000 steps: 93.75\n","The Total Accuracy for Epoch 43: 99.79134063641106\n","Training Loss Epoch: 0.006369084174427068\n","Training Accuracy Epoch: 99.79134063641106\n","Validation Loss per 100 steps: 2.570434808731079\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 88%|████████▊ | 44/50 [1:22:20<11:14, 112.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777, 2.250903172152383, 2.1718828532160543]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327, 61.734693877551024, 64.15816326530613]\n","Validation Loss Epoch: 2.1718828532160543\n","Validation Accuracy Epoch: 64.15816326530613\n","Accuracy on test data = 64.16%\n","Training Loss per 5000 steps: 0.0006405895692296326\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 44: 99.45226917057903\n","Training Loss Epoch: 0.016864515072757057\n","Training Accuracy Epoch: 99.45226917057903\n","Validation Loss per 100 steps: 2.525448799133301\n","Validation Accuracy per 100 steps: 68.75\n"],"name":"stdout"},{"output_type":"stream","text":["\r 90%|█████████ | 45/50 [1:24:13<09:21, 112.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777, 2.250903172152383, 2.1718828532160543, 1.8275868588564348]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327, 61.734693877551024, 64.15816326530613, 65.3061224489796]\n","Validation Loss Epoch: 1.8275868588564348\n","Validation Accuracy Epoch: 65.3061224489796\n","Accuracy on test data = 65.31%\n","Training Loss per 5000 steps: 0.0018391810590401292\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 45: 99.50443401147626\n","Training Loss Epoch: 0.014168927883717212\n","Training Accuracy Epoch: 99.50443401147626\n","Validation Loss per 100 steps: 2.2492480278015137\n","Validation Accuracy per 100 steps: 62.5\n"],"name":"stdout"},{"output_type":"stream","text":["\r 92%|█████████▏| 46/50 [1:26:05<07:29, 112.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777, 2.250903172152383, 2.1718828532160543, 1.8275868588564348, 1.738214689249895]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327, 61.734693877551024, 64.15816326530613, 65.3061224489796, 66.83673469387755]\n","Validation Loss Epoch: 1.738214689249895\n","Validation Accuracy Epoch: 66.83673469387755\n","Accuracy on test data = 66.84%\n","Training Loss per 5000 steps: 0.014058824628591537\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 46: 99.92175273865415\n","Training Loss Epoch: 0.0033600000597592346\n","Training Accuracy Epoch: 99.92175273865415\n","Validation Loss per 100 steps: 2.9930710792541504\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 94%|█████████▍| 47/50 [1:27:57<05:37, 112.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777, 2.250903172152383, 2.1718828532160543, 1.8275868588564348, 1.738214689249895, 2.0979800820350647]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327, 61.734693877551024, 64.15816326530613, 65.3061224489796, 66.83673469387755, 65.9438775510204]\n","Validation Loss Epoch: 2.0979800820350647\n","Validation Accuracy Epoch: 65.9438775510204\n","Accuracy on test data = 65.94%\n","Training Loss per 5000 steps: 9.121068433159962e-05\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 47: 99.58268127282211\n","Training Loss Epoch: 0.012018813632827611\n","Training Accuracy Epoch: 99.58268127282211\n","Validation Loss per 100 steps: 3.0089662075042725\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 96%|█████████▌| 48/50 [1:29:50<03:44, 112.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777, 2.250903172152383, 2.1718828532160543, 1.8275868588564348, 1.738214689249895, 2.0979800820350647, 2.058687618800572]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327, 61.734693877551024, 64.15816326530613, 65.3061224489796, 66.83673469387755, 65.9438775510204, 65.05102040816327]\n","Validation Loss Epoch: 2.058687618800572\n","Validation Accuracy Epoch: 65.05102040816327\n","Accuracy on test data = 65.05%\n","Training Loss per 5000 steps: 0.00016387586947530508\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 48: 99.97391757955138\n","Training Loss Epoch: 0.0019347750743387829\n","Training Accuracy Epoch: 99.97391757955138\n","Validation Loss per 100 steps: 3.0584800243377686\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["\r 98%|█████████▊| 49/50 [1:31:42<01:52, 112.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777, 2.250903172152383, 2.1718828532160543, 1.8275868588564348, 1.738214689249895, 2.0979800820350647, 2.058687618800572, 2.258614420890808]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327, 61.734693877551024, 64.15816326530613, 65.3061224489796, 66.83673469387755, 65.9438775510204, 65.05102040816327, 65.05102040816327]\n","Validation Loss Epoch: 2.258614420890808\n","Validation Accuracy Epoch: 65.05102040816327\n","Accuracy on test data = 65.05%\n","Training Loss per 5000 steps: 0.00010395477147540078\n","Training Accuracy per 5000 steps: 100.0\n","The Total Accuracy for Epoch 49: 99.8435054773083\n","Training Loss Epoch: 0.005094432403651202\n","Training Accuracy Epoch: 99.8435054773083\n","Validation Loss per 100 steps: 3.108414888381958\n","Validation Accuracy per 100 steps: 56.25\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 50/50 [1:33:35<00:00, 112.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["test_losses:  [0.6400099165585577, 0.6569189593500021, 0.6093497683807295, 0.6128950240660687, 0.6521694337835118, 0.8647014705502257, 0.900049084911541, 0.9775705665958171, 1.1360047824528752, 1.481410299028669, 1.3088316613314104, 1.3027345057652922, 1.3971443316157983, 1.5097090796548494, 1.5920255269323076, 1.4352193687643324, 1.5899538142340524, 1.7731321952780899, 1.6994966986228008, 1.3728274578342632, 1.8255518893806302, 1.9168345806550007, 1.8039779237338476, 2.076651930809021, 2.0030470283664004, 1.8041236461425314, 1.818214540578881, 1.8594834901848618, 2.1067855759542815, 2.052985585465723, 1.9276424159809036, 1.6524228642181473, 2.0161510024751936, 1.8548836136350826, 1.985793490799106, 2.0437252460693824, 2.3441052972053993, 2.1530330083808122, 1.8283405200559266, 2.0263126334365533, 2.0230234374805374, 2.022567380447777, 2.250903172152383, 2.1718828532160543, 1.8275868588564348, 1.738214689249895, 2.0979800820350647, 2.058687618800572, 2.258614420890808, 2.3565485732895985]\n","test_accs:  [61.224489795918366, 65.43367346938776, 67.7295918367347, 67.7295918367347, 67.60204081632654, 63.265306122448976, 63.775510204081634, 65.81632653061224, 63.13775510204081, 62.11734693877551, 62.244897959183675, 64.41326530612245, 64.15816326530613, 63.392857142857146, 64.54081632653062, 65.9438775510204, 64.9234693877551, 64.15816326530613, 65.43367346938776, 66.19897959183673, 63.9030612244898, 64.54081632653062, 63.01020408163265, 63.9030612244898, 65.05102040816327, 66.45408163265306, 65.43367346938776, 66.45408163265306, 62.755102040816325, 62.37244897959184, 65.05102040816327, 64.9234693877551, 61.86224489795919, 64.9234693877551, 63.52040816326531, 63.775510204081634, 62.755102040816325, 65.05102040816327, 63.775510204081634, 64.9234693877551, 62.755102040816325, 65.05102040816327, 61.734693877551024, 64.15816326530613, 65.3061224489796, 66.83673469387755, 65.9438775510204, 65.05102040816327, 65.05102040816327, 65.3061224489796]\n","Validation Loss Epoch: 2.3565485732895985\n","Validation Accuracy Epoch: 65.3061224489796\n","Accuracy on test data = 65.31%\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zbbGkSMNWJNF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618312724068,"user_tz":-120,"elapsed":5661156,"user":{"displayName":"Tianyu Mo","photoUrl":"","userId":"10231734080128882793"}},"outputId":"1f97deea-675f-4179-cab9-9a3a021bd284"},"source":["print('This is the test section to print the accuracy and see how it performs')\n","print('Here we are leveraging on the dataloader crearted for the test dataset, the approcah is using more of pytorch')\n","\n","# acc = test(model, testing_loader)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["This is the test section to print the accuracy and see how it performs\n","Here we are leveraging on the dataloader crearted for the test dataset, the approcah is using more of pytorch\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"id":"JWvi1omRZldQ","executionInfo":{"status":"ok","timestamp":1618312724070,"user_tz":-120,"elapsed":5661153,"user":{"displayName":"Tianyu Mo","photoUrl":"","userId":"10231734080128882793"}},"outputId":"0d36b18d-3cf7-4871-dd04-724f1b6f5dd2"},"source":["plt.figure(figsize=(9,4))\n","plt.subplot(1,2,1)\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.plot(train_losses, label=\"train\")\n","plt.plot(test_losses, label=\"test\")\n","plt.grid()\n","\n","plt.subplot(1,2,2)\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy (%)')\n","plt.plot(train_accs, label = \"train\")\n","plt.plot(test_accs, label = \"test\")\n","plt.legend()\n","plt.grid()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAikAAAEGCAYAAACggQVgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXyU1bnA8d+Z7BtZIUCAJOyrsom4B3FFFK0Wl7rbUmu11t5a7b3V7r12vWq1VaxWrRVQ1AqKCiIRcGNXWZJASCAL2UOSyZ7MuX+cCQlkm0lmyUye7+eTz2Teed95n0BIHs55znOU1hohhBBCiIHG4u0AhBBCCCG6IkmKEEIIIQYkSVKEEEIIMSBJkiKEEEKIAUmSFCGEEEIMSIHeDsBZCQkJOiUlxaFza2triYiIcG9ALiBxup6vxOrrce7cubNMaz3UCyH1i/wc8R5fiRN8J1Zfj7PHnyNaa5/6mDNnjnbUpk2bHD7XmyRO1/OVWH09TmCHHgA/F5z9kJ8j3uMrcWrtO7H6epw9/RyR6R4hhBBCDEiSpAghhBBiQJIkRQghhBADkiQpQgghhBiQJEkRQgghxIAkSYoQYkBRSr2glCpRSu3tcCxOKbVBKXXQ/hhrP66UUk8qpQ4ppb5SSs32XuRCCFeTJEUIMdC8CFx2yrGHgY1a6wnARvtzgMuBCfaPZcDfPRSjEMIDfK6ZmxDCzQ68A3VlMOsWsAR4/PZa681KqZRTDi8B0uyfvwSkAw/Zj79s77XwuVIqRik1Qmt9zDPRCuH/ahtbOFJex+ThUVgsqtPrVXXNrPmqEK01KfERpMRHMDImlMCA/o+DSJIiRF8U74eWBkjys9mF1mZY/z8QMgRm3+btaDpK7JB4FAGJ9s+TgLwO5+Xbj3VKUpRSyzCjLSQmJpKenu7Qja1Wq8PnepPE6ZgWm6ayQRMSqBgS3PkXbkd9jbWqUbOnpIWDx23EhSpGRVpIirSQGGHuZ23SVDdpqpuguklTY/+obtJEBSmuGhdESGDn2HKqWnlpXxMBCpKizHuOirQQaqvn+PsfERaoCA4Apcy1rTZNiw3qWzQl9ZriWhsldZqKBs3EOAtnJAYSHtT9n8HxRhsfHmlhU14ztc0QH6o4OymQc0YGMjzCQl6NjY1Hmvm0sIUm28nXBiiYnhDAA3NC+/XnKUmKEH2x7kGoyoMffuXtSFxrz7+hMhdueh1Uzz/AvUVrrZVSug/XLQeWA8ydO1enpaU5dF16ejqOnutN/hin1poPD5RQUtPAyOgwRsSEMiI6jCGhgSd+EXfUatNsy6lgU2YJVXXNNLa00tRqo7HZRlltE8eO11NqbURrsCg4b8JQrp0zikumJhIaFIDWmqMVdew8UkluWS1jAgpY3E2sO49UsPNIJSGBAQQHWggOsFBmbWTD/mJ2Hq1Ea4gND6Kqvhmb/bs1wKJotXX9rRtoUcRFBFNqbeRgXQh/v3kO44ZGnnh9zZeFPPbhl8RHBJMcH8He4ho25zfZX1VA/Yl7BAUomlpsdHWrAIsiOiyITwqbeDWjhUunDecbs5NIjo/A2tBCTWMzNQ0tfHSghLd2F9Bss3Hp1OGcP3Eo7+8r4t2DpazNbiY5Ppwj5fWEBFq4ZvZobj07mYTIEHLLajlSXkdOeS3RYUGkXTDuxL378j0qSYoQztIaSvZBfSVU5EBcqrcjco3mBvj4DzBqHky42NvRnKq4bRpHKTUCKLEfLwBGdzhvlP2YGMDqmlrYkVvJp9nl5JRZWTglkcWnjSA8uP1X0u6jlfz6nf3sOnq80/Ux4UFMHxnN9KRoZiRFExsRxPp9xaz7+hglNY0EB1qICw82yYM9gYiLCGbixKGMjAljZEwoRyvqeGtXAT9YsZuokEBmjonhwLFqyqxNJ+4TGQQjJpRxzviEE8dsNs1fPzrE4xuz0F0kAdNGDuGHCydyybREJg+PorHFRnaplaziGrJLagkKsBAfGUxCZDDxkSHERQSTEBHCkDCTeG05WMr9K/dw1V+38vvrTmPR9BH8eUMmT2/KZl5KHH+7eTYJkSEAlFkbySqu4eMv9jBq7ASTZDQ009xqs3/dAYQEWQgPDmB0XDip8REkxYYRaFF8mV/FGzvzWfNlIWu+LOz0dYQEWlh6xii+fe5YUhLMfjs3nTmG4uoG/rO7gK2Hyrhx3hiunzua2IjgE9clDgnlzLHxzn9TdEOSFCGcZS0xCQrA4XT/SVJ2vQTVBXD13wbiKMoa4DbgMfvj2x2O36uUWgmcCVRJPcrA9emhMn73RT05G9bT3KoJtCgSIkP4YF8xv167n6tnJXH59OG8tiOP/+wpZGhUCH+49jTOm5hA4fEGjlXVc+x4A9mlVr4uqOL5rYdpbjWZQnCghQWThrL4tJEsnDLspISnO/918SQ+zynnjZ0F7C2o4vyJQ5mTHMuc5FgCLRZuXb6ZW57/gocvn8x3zhtLZV0zP1y1h81ZpVw9cyQ/WzwVBTS12mhqsREWFMCwIaEn3SM0KIBpI6OZNjLaoT+j8yYM5d0fnMv3/72Le1/dzcTEg2QVW7nhjNH8asl0ggPb6zwSIkNIiAyhKS+QtPnJjv9FADNHxzBzdAw/WzyFLVllVDc0ExUaRGRIIFGhgYyOCyc6LKjTdYlDQvnuBeP4bocREneSJEUIZ5UeaP/8cDrMvcNrobhMUx1s/hOknAepF3g1FKXUCkyRbIJSKh/4OSY5eU0pdRdwBFhqP30dsAg4BNQBfvCXMTBtPFDMqu152DoMHyiliAkLIj4yhITIYBIiQ1gweViXv9z2FVbx7Zd3EBGgufPcVM4el8Dc5FjCgwPYnlvJim1HWbUjj399foSQQAv3LhjP3WnjiAwxv6ZGRIcBsSe9Z2NLK5lFNRRXNzJ/bBxRoZ3v2xOLRXH2uATOHpfQ5euPzA9jTdEQfrcug+25lewrqKLM2sRvr5nOTfPGdDnl5AojosNYuewsHnsvg1c+P8IvrpzKbWenuOV+IYEBXDQ1sfcTvUSSFCGcVZJhHscthJzNYLOBxcdX829/DmpLYOnLXh9F0Vrf2M1LC7s4VwPfd29E/m9vQRX3r9zNpOFRPLp4GsOj20cDbDbN4x9m8eRHhxgRHUpch6H9Vpvm67pmymsbT4xopCZE8MLtZ5BqnyIAOFZVz50vbicmLIgHZymuuWzKSfeflxrHvNQ4fn7lVD7OKmVOciyjYsN7jTskMIDTRsX098vvVlig4m/fms3fP87mjx9kkhQTxhvfO5sZoxwbFemP4EALj145lZ8umkyQC1bJ+CpJUoRwVukBCIuF05ZC9kYo/hpGnO7tqPquoRq2Pg7jL4Lks7wdjfCwN3fl89M3v2ZIWBAbD5SwOauMBy+dxM3zk7E2tvDDlbvZlFnKdXNG8ZurpxMa1HlZutaamsYWvsw7zv0r93DN3z7hmZvnMH9sPNbGFu56cQe1ja28fvdZFGfu6jaWmPBglsxMcueX6zSlFPekjeeSqYkkDgl1erSmvwZzggKSpAjhvJIMGDqlfVrk8Me+naR88QzUV8CC//F2JMKDmltt/PbdA7z4aS7zx8bx1E2zqW1s4Wf/2cvP1+zjzd0FVNU1kV9Zz6+vns7NZ3Y/vaGUYkhoEOdNGMpb95zNnS9u55bnv+C318zg/b1FZBbX8Pxtc5kyYgjFmR7+Ql1k/LAob4cwKA3uFE0IZ2ltRlKGTYYhIyBhkqlLcYe6CtjwqBnpcBebDb54FiZe7n89X0SXWm2aLQdLuem5z3nx01zuOjeVV+46k4TIEJLjI3j5znk8ccNMCirrqG1qZcWy+dwyP9nheojk+Aje/N45nJESx09Wf8VHGSX84qpppE0a5uavTPgjGUkRwhk1RdBQZUZSAMamwa6XoaURAkNce699b8EnT0CjFRb/xbXv3ab0gOkuO/Uq97y/GDAOFtfwxq4C/rO7gKLqBqLDgnj8+plcPevk6RWlFEtmJnHx1ERsmhOFq86IDg/ipTvn8acPMomNCOYWJ1eeCNFGkhQhnNG2smfYZPM49gLY9izkb4eUc117r/zt5nHH86b+Zcx8174/QM4W8+jq2MWA8tzmw/x23QECLIq0iUN5ZPFUFk4Z1mV9SRtHlvD2JCjAwk8XTen9RCF6IEmKEM5oW9nTNpKSci4oi5nycUeSknqBaRi35j64e6vrR2tyt0BMMsSMce37igFje24Fj72fwcVTE/ndNTMYGuXi7yEh3EhqUoRwRukBCI+HyKHmeWg0JM0xxbOuVFcB5YfMdNLi/4OyLNji4ikfmw1yt0Lqea59XzFgVNQ28YMVuxkVG8afl54uCYrwOZKkCOGMtpU9HaVeAAU7Ta2Kq+TvMI+jzoAJF8GMpbDlz+0jOa5QvBcajpsGbsLv2Gya/3ptD+XWJp6+aTZDPLx0VghXkCRFCEdpDaUZ7fUobcamgW6F3E9cd6/8bWYaqW3FzWX/CyFRsPYHZgTEFXK3mkepR/F5//r8CB/kNnOopAZt7wi7fMthNmWW8rPFU5ie5P7mY0K4g9SkCOGo6kJorIahpyQpo+dBYBjkfAyTF7nmXvnbIXEaBNu7dkYkmETlre/CvjdhxnX9v0fuFohNhehR/X8v4TUvf5bLo2/vA2BFxmaSYsI4c2wcb+8pZNGM4bKyRvg0GUkRwlEnVvacMt0TGGI6tbqqX4qtFfJ3mt2IO5qx1CRDBd137HTqHrmfSD2Kj9ucVcov1+7noinD+OP5Yfz2mulMGzmED/YWMSYunMeuPc1t+8sI4QkykiKEo05d2dNRyrmw8VdQfxzC+rmXSGkGNNWYepSOLBaIH2cKavur6GtorJJ6FB92qMTK91/dxYRhkTx+wyx2fLaVtDOT+daZyTS12NBoQgK7X2IshC+QkRQhHFV6ACKGQkR859faEhdXJBBt/VFGz+v8WtxYqMju/z1ypT+KL6usbeKul7YTEmjhH7fN7dRwLTjQIgmK8AuSpAjhqJKMzvUobRImmseyg/2/T952CIszCcmp4sdDZS60tvTvHrlbIW4cDBnZv/cRHtfQ3Mrdr+zkWFUDy2+d69BuwUL4KklShG8p3gdfrvL8fbWG0szO9ShtYpPBEmj6mfRX/nYz1dNVLUH8OLC1wPEjfX//1hY48qnUo/iguqYWvv3SDrblVvDH605j9phYb4ckhFtJkiJ8y8d/gLeWwdbHPXvfqnxTJ9LdSEpAkBn56G+SUl8JZZkw+oyuX48fbx7LHZzyqTgMq26Gor3tx4q+MquUpB7Fp9Q0NHP7C9v5NLuMP113OktmJvV+kRA+TpIU4VsKd0FAMHz4c9jxT8/dt9ReNNvdSAqYKZ/+TvcU7DSPpxbNtokbZx4drUvJWAcH1sI/LmofgZJ6FJ9TVd/MLc9vY+fRSp64YRbXzpFl42JwkNU9wn3+c4/pwnr9K11PXTirthyOH4ULH4G8bfDOA6bBmSt6hvSmxL78uLuRFICECZD1gZlOCejjP6287YAyrfa7EpEAIdGOF+hWHIaQITD8NDMClb8dyg9C/ASIGt63GIVHVdU1c9M/PieruIa/fWs2l06TvzcxeMhIinAPrSHzPch4x+zi6wrHdpvH0fNg6UuQfLZpbpb1gWvevyelGRCZCOFx3Z+TMBFszf2rF8nfBsOmmuSrK0pB/Fjnpnvix8Otb8PZ98H250w/F6lH8RnPbs7mwLFqlt86VxIUMehIkiLco7oQ6isgKALWP+L4L9WeFNqTlBGnQ1AY3LgSEqfDa7fC8bz+v39PSg70PIoCZnQC+l6XYrOZJm7d1aOcuM9455KUuLFmZOeS38A3X4Lo0TD92r7FKDyqobmVFduOcvHURBZMGubtcITwOElShHsU2ws1r3rSFJW+dbfpctofBbtNIhBq34ckdAgsfRlaGmHXS/17757kbTPNz4bP6Pm8BHtRa1+TlLIs02Ctu3qUNnHjoCoPmht6Pq+lyZzXcSnztKvhgb1Sj+Ij1uwppLKumdvPTvV2KEJ4hdtqUpRSo4GXgURAA8u11k+cco4CngAWAXXA7VprF/T8Fl5X9LV5nHAJLPoTvPkd+OQJOO9HfX/Pwt2df7nGJpt77PoXXPCQSYhcqTwbVtwAMaPh3Ad6PjcsFiKGdZ2kaG2mpmqOQWiMSbTCYkgpKAY+N5sJthXnntoO/1Tx4wENlTk9F/JW5YG2dd1vRQx4Wmv++Wkuk4dHMX9sD9OMQvgxdxbOtgD/pbXepZSKAnYqpTZorfd3OOdyYIL940zg7/ZH4euKvobYFDPaMeObpjZl0+9MQjF8uvPvV1MENYUwclbn1+beYRKJrPdhypW9v9enT5n4vvFsz+fVlsO/rzMJxrdWm6LV3iRMhLIuilpLM+CrVWYkyFpi2uc3HCelpQE6lrDEjWtfZtydeHvSUZ7dc5JScdj+npKk+KJtORUcOFbNY9+YIfvviEHLbUmK1voYcMz+eY1S6gCQBHRMUpYAL2uzt/jnSqkYpdQI+7XClxXvNfUiYIo9r/g/OPIZ/Od78N3Nzq/2KdxjHrtKUsZfDEOSzJJkR5KUzHVw5BO46Ofdd1xtroeVN0JVAdy21jRRc0TCeNi/pvPxHPuy35tXm+TNLj09nbQLLjBTYdpmGsJZepmFbVuG3NsKH0lSfNqLn+YSEx4k/VDEoOaRJchKqRRgFvDFKS8lAR0rHvPtx05KUpRSy4BlAImJiaSnpzt0X6vV6vC53uRvcVpaGzivPJvcqDM40uH8pBFLmHDoOb54byX14SOcundKzpskY2HLoSpsOZ1jSI47n5TslXzx3ioawhJ7jPWsYwcIAbLWPkFh0uWdT9A2pu7/E0NLt7F/6oOUHq53eIfjUcctjK+v4JP1a2gOHnLi+LS9bxIVMozPv8wFck8ct1qtpH/8sUPv3dHZQdGU7dtKVsvMbs8Zf3AzwwNC2bp9b7+XgPvK96i/KDhezwf7ilh2/jjCgmUPHjF4uT1JUUpFAm8AP9RaV/flPbTWy4HlAHPnztVpaWkOXZeeno6j53qT38WZtx22aFLnX0nq5A7nl46AQ89xZmIjzHHgfToqeBqGTeb8hZd1/XrVBHh8FfODMiDt+u5jbaqD9AoAJtqymJj2+87nHNwAH38CF/2Cab3VoXS6thmyX+CcSUMh+SxzzGaDL26HKYs6xdTnv/vsKYy01DGyp2sLnoahE0hbsMD59z+Fr3yP+ot/fWbmAG85K9nLkQjhXW5d3aOUCsIkKP/WWr/ZxSkFwOgOz0fZjwlfVmwvmk08pfYkYaLpNdI29eEorU3RbFdTPW2ik2DiZbD7FWht7v68ylzzGDMGcjab2pBT7XoZwhNg/vedixNMQzcwDdPaFO817e5d2YbekWXIbcuPhU+pb2pl5fajXDptOEkxYd4ORwivcluSYl+58zxwQGv9l25OWwPcqoz5QJXUo/iBoq9NV9SYMScfV8qszsndahIPR1UXQG1pz0kKwJw7oLYEMt7t/pzKHPM4//tmo75DH578em2ZaUJ3+g0QGOx4jG2iR0Ng6MkrfNra0LuygVr8WLAWQWNN16+3tkDlEUlSfNDbewo4XtfM7WeneDsUIbzOnSMp5wC3ABcqpfbYPxYppe5WSt1tP2cdcBg4BDwH3OPGeISnFO01K3i6qoNIOc/8cnW0rTtAgX1Vem9JyviFJknY2cOePm3FpKctNcuFM945+fWvVpmusbNudjy+jiwBprC14x4+OVtMshDtwv1W2lYAtX09p6rON1+HJCk+Z8X2PCYlRjEvVZYdC+HO1T1bgR6r9eyrevowpi4GLJsNivd1/0s+9XzzmLO5fWqkN4W7zaqXU6ePTmUJgNm3wabfEJZwQ9fnVOSYPiXhcTB5EXy92jSDCwwxozu7/gVJc3te2tubhAlmp2EwIxpHPoFp1/T9/brScYXPiNM7v15hHzGSJMWnHCyu4cu84/zsiimy7FgIpOOs6KvGGkj/PTScUgtdmQPNtd13Z40bC1Ej26dAHFG42+xnExTa+7kzbwQgvnx7169XHIY4e/fOyYuhyQqH7atrCnZC6QGYfYvjsXUlYaKpfWlphKIvobG6PTlzlbbko7ybkRRZfuyTVu/KJ9CiuHqWLDsWAiRJEX21+Y+Q/jv44pmTj7d1mu2uYZtSpjbD0boUR4pmO4oeBRHDiKjN6fr1ypz2X9yp50NwZPuUz+5/QVA4TPuGY/fqTsJE0/OkIqe9SNiVRbMAweGmN0x302YVhyEwDCJlQzpf0dJq461dBaRNGkZCZIi3wxFiQJAkRTjv+FH4/BnTyn3b8pP3kCneCyoAhvYwXZJynimEbWsD35PKHGg47niSAjB8OpHW3M7HW5vNRoSx9pGUwBCYcLFp7tZYA1+/AVOvNl1y+yOhw0aDuVsgYRJEJfbvPbsSPw4qulnhU5FjRox6awwnBowth8ooqWnkujkurF0SwsfJTzDhvI2/NiMiVz1lko2vX29/rehrM5LQ09RM2yoXR5Yit+18nDTb8fgSpxNRe7TzUuTjR0G3njwFMnmx+RrWPwJNNf2f6oH2otaS/abLritX9XQUN67nkRSZ6vEpq3fmExsexIWTZbdjIdpIkiKcU7ALvn4N5t8DM28yxayfPd0+ddO2sqcnsSkQPQZyN/d+v8LdEBDS88jMqRKnY9EtJ6+wgQ7FpB12lJ1wMViCzIqguHEw5izH79OdkEgzFfPVKlOf4+qpnjbx403/lbqKk4/bbGYEqkP7fTGwVdU1s2F/MUtmJhEcKD+WhWgj/xqE47SGDY+aRmfnPmBGU876vik2zf7I/LKszu++aLajtroUm637c5rqTDv64dOd61nSliQV7z35eGUXK15Co9tHOmbd3O/28SckTGgvXnVbktK2wueUKZ+aY9DSICMpPmTtV4U0tdhkqkeIU0iSIhwWX77d1FikPdxetzH9OlOc+dlT7UlBb0uFwfzirq+Ekn1dv15VAP+83IzMzL3TuUATJmJTgZ2TlIrDpjA28pT6kNOuh+AoOP1G5+7TSwyA+bOIiHfd+3Z0olfKKUmKrOzxOat35jN5eBTTRvazHkoIPyNJinBMawtjD79kfjHOub39eGAwzPuOGUn56jVzzJGRlJRzzWNXdSlHv4DlaWaE4MaVzjdWCwiiNmK0SXA6qsgxRbOnjpacdj08eAiGOLfpYY/akhR3jaIAxCSb4uVT61L8OElRSt2vlNqrlNqnlPqh/VicUmqDUuqg/THW23E641BJDXvyjnPdnFHSG0WIU0iSIhyzdzURdflw0S8hIOjk1+beaZa77v6XGaWIdKDwL2a0qZno2C+lqRa2/wNeWmzqOr79IUzqZkPBXtRGpHY9ktKxHqWNUo71YHFG4jTzOK7/m/t1KzDY/BnmbTv5eGWOqbNxZYfbAUApNR34DjAPOB1YrJQaDzwMbNRaTwA22p/7jNU7CwiwKJbMlN4oQpxKkhThmGNf0WoJhslXdH4tPA5mfct87shUT5uU8yD3E/jkSXjpKvh9Crz7X5B8Nnx7Iwyb3OdwrZEpYC0Ga6k5YLOZBmtdJSnuMOYsuHM9TLjEvfeZfRvkfAzZm9qPVRw2yYslwL339rwpwBda6zqtdQvwMfANYAnwkv2cl4CrvRRfn3ywr4jzJiQwNEp6owhxKre1xRd+pjqfxpAEwrsbjp5/D2x/vusW7d0Zm2ZGXzY8YlbvzFtm9t9JvaDfv2CtkfZkpPhriLwQagqhtbG9R4q7KQVjznT/fc68G3Y8D+t/Bt/dbP7c/Hf58V7gt0qpeKAeWATsABI7bExaBHTZlEYptQxYBpCYmEh6erpDN7VarQ6f66zGVk1uWR2nxzT1+x7ujNOVfCVO8J1Y/TlOSVKEY6oKTJLS3evx4+Cu9Y7vxwNmP5vgSFPDEu3aoW5rZIr5pGgvjLvQf/eyCQqFi38Fr98Ou1+B2bearzX5XG9H5nJa6wNKqd8D64FaYA/Qeso5WinVZStjrfVyYDnA3LlzdVpamkP3TU9Px9FznbW3oAq9YSuXnjmDtBn9q4lyZ5yu5Ctxgu/E6s9xynTPYGRrhS+eNatrHFVdSENoQs/njJ4HYU7ULFoCTM2JixMUgJagIWaPoLa6lBPFpB4aSfGkqVfD6Pnw0W/M19lk9b9kzE5r/bzWeo7W+nygEsgCipVSIwDsjyXejNEZmUU1AExIjPJyJEIMTJKkDEbZm+C9n8CaHzi2f05rC1iLaAzpJUkZaBKnta/waSsmHeJfxaSAmVq69HdQWwJr7zfH/DEZA5RSw+yPYzD1KK8Ca4Db7KfcBrztneicl1VSQ3CAhZT4bscohRjUJEkZjLI3mscDa05uad8daxFom+8lKcOnQ1mm2Y244jDEjIEAP53hHDUHZixtXy3lpyMpwBtKqf3AWuD7WuvjwGPAxUqpg8BF9uc+IauohnHDIgkMkB/FQnTFT39iix5lf2SKU1sa4N0fQ/I5PU+5VBUA0BjipqZk7pI4HWwtUJpp33DPb39xGwsfNYlnazNEj/Z2NG6hte7UeEZrXQ4s9EI4/ZZVbGVuik+1dRHCoyR9H2yq8s3uwxMuhqv/DrZmWHNvz9M+1W1Jiq+NpNibyhXvbd8V2J/FjDZ9bKZd7dw2AsIrahqaKThez0SpRxGiW5KkDDZt/TTGLTQrci75tRlZ2fF899f4apISNw4CQ83+P001/j+SAjD/brjuBW9HIRxwsMQKIEmKED2QJGWwyd4IUSNgmH1X4bl3mYRl/SOdN6prU10IQRG0BEZ4Lk5XCAg0X2fm++a5p3qkCOGAg8VmZc8kSVKE6JYkKYOJrdWMKoy7sH3/GqVgyVPm8y+e6fq6qnwYMtJ1OwR7UuJ0aKwynw+GkRThMzKLrIQFBTAqNszboQgxYEmSMpgU7jG9UcZdePLxISPNiENpRtfXVRe6pZeJR5zY7FBBbLJXQxGio4MlNUxIjMRi8cHkXwgPkSRlMMn+CFAwtotN7xImQtmhzsfB1KQM8dEkpW0voehRECh7o4iBI7OohgnDZKpHiJ5IkjKYZG+EkTMhooulxPHjzf42jTUnH29thpoiH05S7LsRx6Z4NQwhOjpe10RJTSOThkd6OxQhBl+JX8wAACAASURBVDRJUgaLhmrI29Z5qqdNwkTzWH7KaEpNEaDNlJAvCosxmx6OOsPbkQhxQlaxrOwRwhHSzG2wyNkMutWs5OlK28aAZQdh5Kz249WF5jF6FFjdG6LbfPujfu+qLIQrZdlX9kiSIkTPZCRlsMj+yOw43N2IQtxYUBaTpHRUnW8efXUkBcxSZF9cmST8VlZxDVEhgYyIDvV2KEIMaJKkDBbZGyH1/O47kQaGQEwylGWdfLxtJMVXa1KEGIAyi8zKHiXJsxA9kiTFH5QdhNry7l8vz4bK3O7rUdokTOxck1JVAEEREBrd7zCFEKC1Jqu4hknDZapHiN5IkuLrqvLh2QvgnR92f86hD81jr0nKBJOk2Gztx6oLTI8U+R+fEC5RZm2isq5Zlh8L4QBJUnzd+w9Dcy0c3ABNtV2fc2AtDJ1s9urpScIEszNyVV77MV/ukSLEAHSiHb6MpAjRK0lSfFnWepOAjL8YWurbR0w6spbCkU9g6pLe369tGXLH4tnqQklShHChTHuSMiFReqQI0RtJUnxVcz2s+7FJLJa+DGFxJmE5VcY7oG0w5are3zPevgy53J6ktDVy89WW+EIMQFnFVmLDgxgaKR2QheiN9EnxVVv+DMePwG1rITgcJi+C/WugpfHk9u8H1pjlxW2dV3sSkQChMe0rfHy9kZvwOqVULDASqAdytda2Xi7xe1nFNUxMjJKVPUI4wG0jKUqpF5RSJUqpvd28nqaUqlJK7bF/POquWPxO2UHY+jicdr1ZVgxmpKSxGg5/3H5eXYVp4jZ1iWOFr0qZupS26Z7qAvM4ZJRr4xd+TSkVrZT6b6XU18DnwLPAa8ARpdTrSqkuNo8aHNpW9kgTNyEc487pnheBy3o5Z4vWeqb941dujMV/aA3v/siMnlzym/bjY9MgOMqMnLTJfA9sLY5N9bRJmNhFkiIjKcIpq4E84Dyt9SSt9bla67la69HAY8ASpdRd3g3RO4qqG6hpaGGi1KMI4RC3TfdorTcrpVLc9f6D1uF0Mzpy+R8hclj78cAQmHgpZK6D1hbTZXX/2xA95uQ2972JHw97/m32+qmyJylSkyKcoLW+uIfXdgI7PRjOgJJZ1LayZ4iXIxHCN3i7JuUspdSXQCHwY631vq5OUkotA5YBJCYmkp6e7tCbW61Wh8/1JmfinPHVr4kKiuGz2lT0Kdck6HFMr1vNnjV/oyZqHOcc2khB0hVkf/xx12/WhYTSJqYDO9evIrH4C4YHhLL1s12glM/8eYJ//t17U3/iVEoNBe4HwoBntNYHe7nEb7Xv2SMjKUI4wptJyi4gWWttVUotAv4DTOjqRK31cmA5wNy5c3VaWppDN0hPT8fRcz2iuR7+Ohcu+TVM/8aJww7HWZIB6Tthwc+44IIu/rPadAZkPsnMkDwYNhx0C6MvvZfRo+c5HmPpCNj3v8xJHgL1ChqTSVuwwLk4BwBfiXWQxPln4DlAA68Cg3ZL6qxiK8OiQogJ72Z7CiHESby2BFlrXa21tto/XwcEKaUSvBWPR5QfMhv2fbmyb9d/9hQEhsEZ3UznB0fA+IVmKfL+tyFqBCTNde4esamgAswKn6oCqUcRTlNKfaCUOr/DoWAg1/4xqNfdSjt8IZzjtSRFKTVc2dfgKaXm2WPpYQMaP9C2L07OZjOq4gxrCXy1CmbeBOFx3Z835SqoOQYZ78KUK8Hi5F9xYDDEppheKdWFUo8i+mIpcKVSaoVSahzwCPC/wBPAPV6NzItsNlnZI4Sz3Dbdo5RaAaQBCUqpfODnQBCA1voZ4Drge0qpFkwPhRu01tpd8QwI5dnmsaUecrfChG7rCzvb9pxprja/l5/xEy8FSxDYmh3rMtuVhIlQvB+sxdJtVjhNa10FPKiUGgv8FlNzdq/W+rh3I/OuvMo6GpptUo8ihBPcubrnxl5efwp4yl33H5AqDkN4AjTXQdYHjicpzfWw/R8w6XJIGN/zuWExMG4BHPsSxpzVtzgTxkPWe+ZzSVKEk+yjJ98DmoD/AsYBq5RS7wJPa61bvRmft2QVWwFkJEUIJ0hbfE8qP2Q2+hubBgc/MD1PHPHlCqivgLPudez8JU/D7evAEtC3ONv28AFJUkRfrADeBDYB/9Jab9FaXwocB9Z7NTIvyjqxZ48kKUI4SpIUTyrPhvixZgTl+FEozez9GpsNPnva9DpJPtux+0QO633EpSfxHRZZSU2KcF4IkIMplA1vO6i1fhlY7KWYvC6zqIZRsWFEhni784MQvkP+tXhK/XGoKzPN0iZcYo4d/ACGTe75usx1ZgTm2ucda23vCieNpMjqHuG0ezBTuU3A3R1f0Fo7WTHuP7KKa5gkoyhCOEVGUjylwl40GzcOokdB4nTI6mXk29YKH/3GXNPXIti+iIiHsFjTZj802nP3FX5Ba/2J1vparfWNWusvvR3PQNDcaiO71CpTPUI4SZIUTyk/bB7j7dMwEy6Bo59BQ1X313y1CkoPwMJHICDI/TF2lDBRpnpEnyil1iqlFiulOn3TKqXGKqV+pZS60xuxecuR8lqaWzWThsvKHiGcIdM9nlJ+CFCmBwmYpcJb/wLZHwGxnc9vboBNvzO1KFOv9mCgdhf9wqxCEsJ53wF+BDyhlKoASoFQIAXIBp7SWr/tvfA8L7NIVvaI7jU3N5Ofn09DQ0Ofro+OjubAgQMujsr1IiMjaW5uJijI8f90S5LiKRXZED0agkLN81FnmCmVrPUQe33n83c8D1V5sOQpz9WidORoka4Qp9BaFwE/AX5i32R0BKYXUpbWelBmvpnFNVgUjBsqIymis/z8fKKiokhJSUH14ed9TU0NUVEDOwHWWpOfn09+fj6pqakOXyfTPZ5Sfgjix7U/twTAuIVwaANo28nnNlTB5j+Zpcpj0zwXoxAuprXO1Vp/prXeM1gTFICsohpS4iMIDepjWwDh1xoaGoiPj+9TguIrlFJER0c7PVokSYonaG1qUjomKWCmfGpLiao5dPLxT/9q+qJc9AtPRSiEcCNphy96488JSpu+fI2SpHhCXTk0VplVOh2NvwiUheQjr8GeFaZV/rEvTV+UadeYehQhhE9raG4lt7yWibKxoBigjh8/zt/+9jenr1u0aBHHj7t3twtJUjyhbWPB+FMarIXHwdQlJJRvh//cDS9eAc+eDy2NcOEjno9TCBdSSl2plBr0P2OyS63YNNIjRQxY3SUpLS0tPV63bt06YmJi3BUWIIWzntG2seCp0z0A33yRzXE3cf7McaYLbVUeRA7v+lwhfMv1wONKqTeAF7TWGf19Q6XUA8C3AQ18DdyBKcxdCcQDO4FbtNZN/b2Xq7S1w5flx2Kgevjhh8nOzmbmzJkEBQURGhpKbGwsGRkZZGVlcfXVV5OXl0dDQwP3338/y5YtAyAlJYUdO3ZgtVq5/PLLOffcc/n0009JSkri7bffJiwsrN+xSZLiCeWHwBIIMWO6fNkWEGySEklMhB/RWt+slBoC3Ai8qJTSwD+BFVrrGmffTymVBPwAmKq1rldKvQbcACwC/k9rvVIp9QxwF/B3l30h/ZRZZCUoQJEcH+HtUIQP+OXafewvrHbqmtbWVgICui/KnjpyCD+/clq3rz/22GPs3buXPXv2kJ6ezhVXXMHevXtPrMJ54YUXiIuLo76+njPOOINrr72W+Pj4k97j4MGDrFixgueee46lS5fyxhtvcPPNNzv1dXTFoaFYpVRE27CtUmqiUuqqrho1iW5UZENMsucbsgnhZVrramA1ZqRjBHANsEspdV8f3zIQCFNKBWL2BToGXGi/B8BLgBcaC3Uvq7iGcUMjCQoY9DNfwkfMmzfvpGXCTz75JKeffjrz588nLy+PgwcPdromNTWVmTNnAjBnzhxyc3NdEoujIymbgfOUUrGYXUy3Y4Zyv+WSKPxdVyt7hPBzSqmrMNMx44GXgXla6xKlVDiwH/irM++ntS5QSv0JOIrpu7IeM71zXGvdNnmeD3TZKlkptQxYBpCYmEh6erpD97VarQ6f25WvjtQxPsbSr/dwRH/j9BRfiRM8F2t0dDQ1NWZw8UdpXY+496S3kRTgxPt3xWq1YrPZqKmpoa6ujpCQkBPnb9myhQ8++ID169cTHh7OokWLqKiooKamBq01VqsVq9VKUFDQiWtaWlqora3tdM/W1lYaGhqc+jN1NElRWus6pdRdwN+01n9QSu1x+C6DmdZmJCX1PG9HIoSnXYuZhtnc8WCHnyVOsf8naQmQChwHXgcuc/R6rfVyYDnA3LlzdVpamkPXpaen4+i5p7I2tlD2/gfccf540tL6sTO5A/oTpyf5SpzguVgPHDjQr2Zs/W3mNmLECGpra4mKiiI8PJzAwMAT79fc3ExCQgKJiYlkZGSwfft2wsPDiYqKQilFZKSptbJYLCeuCQkJobm5uVNMNTU1hIaGMmuW4ytXHU5SlFJnYUZO2n64SFciR9QcM+3l48Z6OxIhPO0XmOkYAJRSYUCivcHbxj6830VAjta61P5+bwLnADFKqUD7aMoooKDfkbvIQXvR7IRhUjQrBq74+HjOOeccpk+fTlhYGImJiSdeu+yyy3jmmWeYMmUKkyZNYv78+R6NzdEk5YfAT4G3tNb7lFJjgU3uC8uPdLf8WAj/9zrQcX+FVvuxM/r4fkeB+fbponpgIbAD87PoOkzdy23AgNkX6FCJ2bNHdj8WA92rr77a5fGQkBDee++9Ll9rqztJSEhg7969J47/+Mc/dllcDiUpWuuPgY8B7AW0ZVrrH7gsCn/W0/JjIfxbYMelwFrrJqVUcF/fTGv9hVJqNbALaAF2Y6Zv3gVWKqV+Yz/2fP/Cdp3c8loCLIpRsf1fiinEYOTo6p5XlVJDlFIRwF5gv1LqQfeG5icqsiEgBIaM8nYkQnhaqb14FgCl1BKgrD9vqLX+udZ6stZ6utb6Fq11o9b6sNZ6ntZ6vNb6m1rrxn5H7iK55XWMjg2TlT1C9JGj/3Km2pcSXg28hylcu8VtUfmT8mxTj2KRH1Ji0Lkb+G+l1FGlVB7wEPBdL8fkUblltaQkSH8UIfrK0ZqUIHtflKuBp7TWzfbGTKI35dmQMMHbUQjhcVrrbEwNSaT9udXLIXmU1prcslrOSInzdihC+CxHk5RngVzgS2CzUioZcK4l3mBka4XKHJjk8CpJIfyKUuoKYBoQ2rYDqtb6V14NykNKrY3UNrWSKiMpQvSZo4WzTwJPdjh0RCm1wD0h+ZGqPGht6rz7sRCDgL1FfTiwAPgHZgXONq8G5UG5ZXUAMt0jRD84WjgbrZT6i1Jqh/3jz4D8y+tNaaZ5lJU9YnA6W2t9K1Cptf4lcBYw0csxeUxuWS0AqbJnjxjgutsF2RGPP/44dXV1Lo6onaPVnC8ANcBS+0c1ZqMw0ZOsDyAoHJLmeDsSIbyhwf5Yp5QaCTRj9u8ZFHLKawkKUIyMCfV2KEL0aCAnKY7WpIzTWl/b4fkvpS1+L2w2yHgXxl8EQdIjQQxKa5VSMcAfMb1NNPCcd0PynNyyWkbHhRMoy4/FAPfwww+TnZ3NzJkzufjiixk2bBivvfYajY2NXHPNNfzyl7+ktraWpUuXkp+fT2trK4888gjFxcUUFhayYMECEhIS2LTJ9T1eHU1S6pVS52qttwIopc7BdHwU3SnYAdYimHKltyMRwuPsTR83aq2PA28opd4BQrXWVV4OzWNyympJkake4az3Hoair526JKy1BQJ6+HU+fAZc/li3Lz/22GPs3buXPXv2sH79elavXs22bdvQWnPVVVexefNmSktLGTlyJO+++y4AVVVVREdH85e//IVNmzaRkJDgVMyOcjTFvxt4WimVq5TKBZ5ikPU7cNqBtWAJggmXeDsSITxOa20Dnu7wvHEwJShaa46U10mSInzO+vXrWb9+PbNmzWL27NlkZGRw8OBBZsyYwYYNG3jooYfYsmUL0dHRHonH0dU9XwKnK6WG2J9XK6V+CHzlzuB8ltYmSUk9H8JivB2NEN6yUSl1LfCm1npQ9VUqrm6kvrmV1IRwb4cifE0PIx7dqe/nLsgdaa356U9/yne/23kcYteuXaxbt46f/exnLFy4kEcffdQl9+yJU5OlWutqe+dZgB+5IR7/ULLf9EeRqR4xuH0Xs6Fgo1KqWilVo5QaFP2Vcuwre2T5sfAFUVFR1NSYHbsvvfRSXnjhBaxW03uxoKCAkpISCgsLCQ8P5+abb+bBBx9k165dna51B0drUrqiXBaFvzmwFlAw+QpvRyKE12itB+3Wv7nl9iRFpnuED4iPj+ecc85h+vTpXH755dx0002cddZZAERGRvLKK69w6NAhHnzwQSwWC0FBQfz9738HYNmyZVx22WWMHDnSq4WzXRlUw7dOOfAOjJkPkcO8HYkQXqOUOr+r41rrzZ6OxdNyy2oJDrAwMkZW9gnf8Oqrr570/P777z/p+bhx47j00ks7XXffffdx3333uS2uHpMUpVQNXScjCujxX59S6gVgMVCitZ7exesKeAJYBNQBt2utdzkY98BVkQPFX8Mlv/V2JEJ4W8ed0kOBecBO4ELvhOM5OWW1jIkPJ8AiA85C9EePSUo/h2tfxKwCermb1y8HJtg/zgT+bn/0bRnvmMcpi70bhxBeprU+qShLKTUaeNxL4XhUbrksPxbCFdzWZcg+pFvRwylLgJe18TkQo5Ty/W6UB9aaNemxKd6ORIiBJh+Y4u0g3M1mM8uPZWWPEP3Xn5qU/koC8jo8z7cfO3bqiUqpZcAygMTERNLT0x26gdVqdfhcVwhurOSsvG3kptzIESfu6+k4+8pX4gTfidWf41RK/ZX26WILMBPTedavHatuoLHFJit7hFO01rTtFO6v+tKJwJtJisO01suB5QBz587VaWlpDl2Xnp6Oo+e6xBfLAU3q5feRmjjV4cs8Hmcf+Uqc4Dux+nmcOzp83gKs0Fp/4rKgBijZWFA4KzQ0lPLycuLj4/02UdFaU1VVRWioc3tZeTNJKQBGd3g+yn7MN9WWw8ePQdJcGOb3I9pCOGI10KC1bgVQSgUopcK11u7bjWwAkB4pwlmjRo0iPz+f0tLSPl3f0NDg9C9/b6itreX000936hpvJilrgHuVUisxBbNVWutOUz0+4/2HoKEarvor+GkmLISTNgIXAVb78zBgPXC21yLygNyyWkICLQwfMvB/aYiBISgoiNTU1D5fn56ezqxZs1wYkXukp6cTFBTk1DVuS1KUUiuANCBBKZUP/BwIAtBaPwOswyw/PoRZgnyHu2Jxu8z34evXIe2n4MQ0jxB+LlRr3ZagoLW2KqX8vpo0175nj0WWHwvRb25LUrTWN/byuga+7677e0xDFbzzAAybCufKTgFCdFCrlJrd1v9IKTWHQbB7em55LeOGylSPEK7gE4WzA9qGR8FaBDe8AoHB3o5GiIHkh8DrSqlCTAPI4cD13g3JvVptmqPldSycIt2mhXAFSVL6I2cz7HwRzr4PkuZ4OxohBhSt9Xal1GRgkv1Qpta62ZsxuVvh8XqaWm2yskcIF3FbMze/pjV8uQpWfgtiUyHtv70dkRADjlLq+0CE1nqv1novEKmUusfbcbnTiY0FZWWPEC4hSYqz6ipg9R3w1jJTh3Lr2xDs97WAQvTFd7TWx9ueaK0rge94MR63a+uRIi3xhXANme5xxuGP4a27obYELnwEzn0ALAHejkqIgSpAKaXsRfIopQIAvy7cyi6tJTw4gMQhId4ORQi/IEmKo5pq4dXrIXoU3PghjBz4a9KF8LL3gVVKqWftz79rP+a3MotqmJgY5bddQ4XwNElSHJW/HVrq4bLHJEERwjEPYfbc+p79+QbgOe+F415aazKKqrls+nBvhyKE35CaFEcd+QyUBUbP83YkQvgErbVNa/2M1vo6rfV1wH7gr96Oy11KahqprGtmUmKUt0MRwm/ISIqjjn4KidMhdIi3IxHCZyilZgE3AkuBHOBN70bkPhlFNQBMHiE/I4RwFUlSHNHaDPk7YPat3o5EiAFPKTURk5jcCJQBqwCltV7g1cDcLONYNQCTh8tIihCuIkmKI459Bc11MGa+tyMRwhdkAFuAxVrrQwBKqQe8G5L7ZRTVMCI6lJhwv17AJIRHSU2KI45+ah7H+PXmrUK4yjeAY8AmpdRzSqmFmLb4fu3AsWoZRRHCxSRJccSRzyBuLEQlejsSIQY8rfV/tNY3AJOBTZg9fIYppf6ulLrEu9G5R3OrjexSK5OGSz2KEK4kSUpvbDY4+pmMogjhJK11rdb6Va31lcAoYDdmWbLfOVxaS3OrZsoIGUkRwpUkSelN+UGor5B6FCH6QWtdqbVerrVe6O1Y3CGjqK1oVkZShHAlSVJ6c8Rej5IsIylCeJNSapJSak+Hj2ql1A+VUnFKqQ1KqYP2x1hPx3bgWA1BAYqxQ2XPHiFcSZKU3hz9DCKGmZoUIYTXaK0ztdYztdYzgTlAHfAW8DCwUWs9Adhof+5RGUXVjBsaSVCA/EgVwpXkX1RvjnwGyWeB7MUhxECyEMjWWh8BlgAv2Y+/BFzt6WAyjtUwRZq4CeFy0ielJ1X5UHUUzrrH25EIIU52A7DC/nmi1vqY/fMioMtleEqpZZi9hEhMTCQ9Pd2hG1mt1h7PtTZpiqobCKorcfg93aG3OAcKX4kTfCdWf45TkpSeHP3cPI45y7txCCFOUEoFA1cBPz31Na21Vkrprq7TWi8HlgPMnTtXp6WlOXS/9PR0ejr388Pl8NHnXHHOLC6YONSh93SH3uIcKHwlTvCdWP05Tr+d7tmUUYJNd/mzynFHPoXgKBg+wzVBCSFc4XJgl9a62P68WCk1AsD+WOLJYNra4U+RRm5CuJxfJinbciq448Xt/GVHI2XWxr6/0dHPzK7HlgDXBSeE6K8baZ/qAVgD3Gb//DbgbU8Gk1FUQ2x4EEOjQjx5WyEGBb9MUs5IieV318wgo7KVWx9/m5x3/wKvXAfbnnP8TeoqoGS/TPUIMYAopSKAizl5N+XHgIuVUgeBi+zPPeZAUQ2Thw9BSXG9EC7nlzUpqr6Sm3ifC+P+yTDrASzbNbVB8UQc2gDWEljw3z2v1qnMhVW3mM/H+2XvKSF8kta6Fog/5Vg5ZrWPx9lsmqyiGm6YN9obtxfC7/nlSArWYnjvQaJsVprPe4j/TX2JGTVPkB5xGWz+A7z/sGl335WDG+DZC6DyCNy4EpJmezZ2IYTPOFpRR31zK1Ok06wQbuGXIykMmwL37mT73nzS0tJ4WGuSt+XxnTUWfhMWxPVfPAONVrjqSVNvYmuFhirYthzSH4PE6XD9y9LATQjRo7Z2+JOkaFYIt/DPJAUgYTyQD4BSipvOHMOk4VHc80owJbYQ7tvzChzaAC0NJkFpc/pNcMWfITjcO3ELIXzGgWM1KAUTEyVJEcId/DdJ6cKc5FjW/uA8vv/vCI7mxXFH6FGmjB2DCouDsFiIH29qUKQATgjhgIyialLjIwgLlhWAQrjDoEpSAIZFhfLvb8/n0bcjWbQ9jx9Pnci9CyZ4OywhhA9acORJfqO2wRMdlh8HhkFcKsSmmsfEabJBqRB9NOiSFIDgQAu/u2YGjS02/rQ+i+jwYG6Zn+ztsIQQPqS6+CjXNa+lfMgUGD29/YVGK1TmQPYmaKk3x5Z9DCNneidQIXzYoExSACwWxR+uO43q+mYefXsv0WFBXHX6SG+HJYTwEZWf/ZMhykZu2hMkzjmj8wlaQ/E+eOYcyPtCkhQh+sA/lyA7KCjAwtPfms0ZyXH8aNUe0jM92k1bCOGrbK3EZaxga+s0xk06retzlILh0yFqBBTs9Gx8QviJQZ2kAIQGBfCP2+cyMTGKe/69i6KqBm+HJIQY6LI3EdVwjPdDLiMhspd2+ElzJEkRvuXLVbDxV6Y9h5e5NUlRSl2mlMpUSh1SSj3cxeu3K6VKlVJ77B/fdmc83RkSGsSzt8yhpVXzlw2Z3ghBCOFLdv6TShVN6aiLez83aTaUH4L6SvfHJUR/VebC2h/Alj/Dm9+B1mavhuO2JEUpFQA8jdmxdCpwo1JqahenrtJaz7R//MNd8fRmdFw4t56VzOs78080aBJCiE6qj6Ez32NV8/lMGRXf+/lJc8xjwS73xjVYHXgHnpjZ/Z9vbbnpIv7JE56Ny1e9/1NQAXDO/bD3DVh9B7Q0eS0cd46kzAMOaa0Pa62bgJXAEjfer9/uvXA8USGB/O+6DG+HIoQYqPa8gtKtrGhdwPSR0b2fP3IWoAZfktLcAO89BJ8/47571JaZ//VX5sC/vwnl2Se/3lQLry6FY3vg69Xui8NfZH0Amesg7SG4+Fdw2WNwYC28dov5+/QCd67uSQLyOjzPB87s4rxrlVLnA1nAA1rrvFNPUEotA5YBJCYmkp6e7lAAVqvV4XPbXJ5sYVVmKU+v3si0BM80aOpLnN7gK3GC78QqcfoYWyvsfJnCuDM5UjicaUkO7NkTGg0JE32vLiXjXWisgdNvcP7ammJYeRMU7ICgCJj1LQhxQ1fe9x6ChmpY+i9Yez+88g24awNEDjPTFK/fDoW7IOU8yN0K9cchLMb1cfiD5gZ47yfme/XM75lj878HAcHw7o9g5Y1w/b893o3d20uQ1wIrtNaNSqnvAi8BF556ktZ6ObAcYO7cuTotLc2hN09PT8fRc9ucdW4rn/z5Y94tCOJ73zgXi8X93Wf7Eqc3+Eqc4DuxSpw+JnsTVB1l46g7iY8IZviQUMeuS5oDhz40y5J762i94edweJPpreKt7tdlB+H1O6C10fyyn32L49ce+wpW3Aj1FXD+T8ymrl+vhrl3uDbGjHdh72pY8D8w9SoYMhJeuhL+fR3c9o6Ztji4Hhb/n/nF++IVcPQzmHS5a+PwF588YepRbn0bAoPbj59xFwSGwNv3mlGpm1ZBcITHwnLndE8Bd1B6+gAAIABJREFU0HH/8lH2Yydorcu11o32p/8A5rgxHoeEBAbw4KWT2H+smrd2F/R+gRBi8Nj5TwhP4HXr6UxLikY5mkQkzYbaEqjqNFB8sroK+OJZOPal96aHbDbzCykozIxArL0fMt937NoDa+GFSwENd74PC/7bbNi685+ujbH+OLzzI0icAec+YI6NmgvffAmK9sLTZ8KeV+CCh2HunZA0FwJCzGiK6KwyF7b+BaZdA2PTOr8+62b4xnI48gm8cq0ZvfIQdyYp24EJSqlUpVQwcAOwpuMJSqkRHZ5eBRxwYzwOu/K0kZw2Kpo/rc+kodn7S7CEEANAYw1kvkfLaTewv6SB6SMdmOppc6J4tpcpn+3Pmy61lkBTtOgN25+DvM9NPcKNK2HEaWbaJG9bz9cd/QJeuw2GTYXvbIIRp5uRoDm3m6SrcLfrYlz/P1BbCkuegoCg9uMTL4Gr/go1hea+afZFpUGhMOoMSVK6ojWs+4kplr3kt92fd9pSuO4FyN8O/7rGJIpdabSapHbdg7Dh0X6H57YkRWvdAtwLfIBJPl7TWu9TSv1KKXWV/bQfKKX2KaW+BH4A3O6ueJxhsSh+evkUjlU18MrnR7wdjhBiICjYBbqVvOh5tNg005McKJptkzjd/E++pySluQG2LYfxF8GES2Hfm2ZUw5Mqc+HDX5gYTr8BQiLhptdhyAgz1F/aTYuG+uPwxrchehTc8hZEJba/NuObZj+jHS4aTTm0EXa/YlafdNXFd9a34IH9sPjxk6fLUs6Foq9O3vW+O63N8NnTjChcDzmboSrfM38Xx/PMaFR/lBwwBbCO2vp/cPADWPgIRCf1fO60a2DpyybpfGkxfPSb9o8PfwEvLobfp8CK683fUU1xf74SwM19UrTW67TWE7XW/9/enYdHXV4LHP+e2bIvJEASkrCFhC0gm+AKKKhYbVHQaqutWltre91ae2vtXnvbXnvvra3VWrQttYhad6k7IotKZZFFWQQhBAhLFiAkk2WSzLz3j3cik5CQhYSZhPN5nnmY+c1k5szCO2fe5bw5xphfBY/91BizKHj+XmPMaGPMGcaYC4wxEbOs5uycVM4dlsqfl++kuq4h3OEopcKtaA0A6/xDARjdkZ4Ul8f2SBSdIEn5+Fk7JHT2bZA/ByoP2DkUp4oxsOgO+4s69As+vh9c/4Lt3VlwpS313/zvXvkOVOyDuX+F6GavS0wy5M+181J8lScXY/leeOEW6DcCpt3T+u2SMo+fzzP4PDAB2PNB24/zyavw5g8Zvv1hO8/lgdHw6wxYt6D1v9n8EvxlZvuSoNa88h345/WwZVHL15fvtY+x853W72PRHfDMV6G+pu3H+/RtW7Rt9ByYcmv7YhxxGXzpKZu4vft/x07v/8EOV571LTuv5Z5CmDOvffd5Aqd9xdkT+c7MPMq8ddqbopSCorWQmsv6MkiIdjEwpYOrHDIn2qWw/hZ+9BgD/37I9rgMnQ55s2zvw6kc8ln3D9i1HC6+D5Kzm16XMsT2kJgA/PVi2Pb6ses2PmV7fS64F7Jb2MMI7NBLfdXxy4CNaX+Ru/oa+wXe4INrnrBDOB2RNcmuVCl8t+3bbnoe4vrzwZR59gv38gfsxNx1j7f+Nx/+3Sayb/2kY3E1OrLbTq52uGHR7XC02ZzI+hr453X2MZb+puX7KN4MRauhoRZ2rzzx4x3aCc9/ze7SPfuhjk3Szr3IJiE/O9L09O2VcPEv7WfY1UYl5nbSJOUEJg1O4fzcvsxbXqC9KUqdzoyxXw5ZZ7JpXwWjByS2f9Jso8yJUF8NpS10GO942x4/53b7ZREVD8NnwZaXW05q2rJ7Jaz4X5tYtae0eel2ePNHdqLshBtbvk36GPjGO5A6zK7eee/39ovu1e/BoPPgvO+2fv9Zk46fQFt1yNbf+O1QKFh+4vgae2sObLATOPvmtv2cmnPHBOelvH/i29VW2FVBo6+gNibdfuFO+hqMvda+nt7Slv+m8D2ITbWJTMGyjse3foF9769/3g43vfjNY++dMfCvu+wwy/DLbCLS0hyfD/9uhxWdnhP3tvi88PR1gNiE7xSu1ukoTVLacNfMPA5V1bHg39qbotRpq3w3VJfhz5zI1gMV7Svi1tyJJs+u/KPdiHD0nGPH8udCdRkUrujY4wQC8NK34Z1fwl9mwP/k2ImvHz9nv+yaqz1qa5q4ouDKP4PjBF8LiQPgptdh1Gx4+2fw6AV24uqceeA4QV2pkAm08ZU7YPtb8Kez7NyJ2FR47Xsnrmq6ap7tsZl+L4z4XHtfieMNOtcmOidanbLtddsTkT+36fHhswBj5280t/MdCNTDnMcgJccOufi87Y/LX2+HkoZdBEOnwef+x/b4vPeAvX7Vn+Gjp2H6D+HKR2ztmdWPNb2Pumq7586o2TDwrNaTFGPg5W9D2Ta4er7tJYtgmqS0YeKgPkzN68e8FQVU+bQ3RanTUtFaAPbG5uNrCHRs0myjlKEQnWwLnIU68JEdZpnyzab1KYZdBJ6Ejg/57HjbVmC97P/sHJG8S2H3v+H5m+18jtDKoYEAvHirvf0XH7cTX9viiYWr/24ThoYaO1TQnr8LTqDN33Q/PHk1xPWzq4Bm/wnKtsMHf2r573a9C2/+0PYgTP1+u16CVrVnXsrmFyAxC7ImNz2ePhYSBjQd6mq0/Q373g6ZZl+P8t02SWyv7W+C9+CxWjLjvmyTpKW/hvcftL1cIy6Hqf9piwOeca1NOqsOhcT9IviO2mQwZwaUbIGK/cc/VuF7tofuwh9DznFlySKOJint8J2ZuRyuquMf2pui1OmpaA24Y1lXkw5AfnsqzTYnEtwROaT+ia/Sroxwx9kvl1DuaBh5uV3t0ZG9U1bPg/h0GP9VGHOV/eV99ycw46fw8TO2qFnjqosVv7Vl0C/5tf0C78hzmf4DuLcIRn6+fX8TkwxjrybKVwrn3AG3LIX0fLtsePhlsPy3x8/D2PehnYeRmtN2L097ZJ1ph0J2t7IUufqwXT2Uf+XxjyUCeZfYgn5NEj2/HR7KvRicLhh0Dky+xfb+NCZDNeU2MXj9npZ70j6cbxOgYRcde6zLfgeJmbD4J/b5X/HIsZgmf8MW2lv/j5D7+LstWjfoHBg2wx5rqTdlw0KISjxWVTbCaZLSDuMH9mH68H48umInXu1NUer0U7QGBkxg08FqYtxOhvSN79z9ZE60v3Brj8Lav8GD4+3wwdTvQUyf428/eo697YnmF4Q6tNP2pEy6qWmvjAicf7edf1CyBR67wM4pWfYbOOPL9ku1Mzo6OXLW/aye/IidXBn6t7N+A8Zv65802rMKHp9teyiue+74VUOd4Ym170Fr9VI+ecUO2zQf6mk0/FI7ATg0ySlaC9WHgsNBQTN+BknZ8Pw37ETj3w61K25W/RkWzGm6lPvIbpsYTfiKTXIaxSTb4ZjB58O1TzZ9/v1HwpCptq6Ov4E4b6GdpzLxRvtep+VDfJq931C+Spssjb7ylJe37yxNUtrprpl5HKmuZ/57u8IdilLqFHL46+yQTNYkNu0/ysiMBJyd3S4jc6Idbnhosp0ImpoLX38Hzm9l0unQ6TZ5ae+Qz+rH7OqQia2UoB/5eVsJFuyckgHj7cqVU1V+3xNLTWzG8cf7DLJJ1OYXbU9F4Xt2uXN8fzsHps+groth8Hmwf0PLy6E3PQ99hkBGC/VXwCYGrpimFXi3v26XZ+fMOHYsKh5m/xG8xeCvs1Vxb3odbvvQ9uQsmHOs12jdP+zrP76FrQeyJsGNr7Q8UXjyLbaC8fY3yDjwlr3fM75krxOxQzkFS5tOnN78op28Pf76E79GEUSTlHYal53MxaPSmLeigDKvr+0/UEr1CvHeAgjUE8icyJb9FZ2bj9Io60xwRdvVFNcshJteg6wT7Abi8sDIL9ghmTaW6jobamxX/qjZTYupNZdxhp0Lcu5d9hd6R5fydpdz7rAJwqLb4Ymr7DLom15ru8BYRw061/ba7FnV9Li3xBZuy5/betLmjoGcC+wclMZJyNvegIFnH79x4dDp8ONiuGWZLZQ26BzoOwyuf872ji28yu7ivP4JO8zTfNl3W/Iutb01K/9I+sFl9n2PTTl2fc4M+5nZv+HYsfULbWKc1cpS8QikSUoH3HPpCGrq/fzh7U/DHYpS6hRJrLBd8yWJY/D6GshLO4ndfONS4c6N8B+r7HyT9vRgTPqa/TX+1JdPWKArrXgZ+CraN3STkAYX/cKu1okU7mi49H7bO5Ay1G4SmJDe9Y+TPdn2NjWvl7LlZdvL1dpQT6O8WTbG4s22Qm/p1tY3LWzp/c04A659wm7iOG9q0wmzHeF02c/G3g9w+auO7z3LuQAQ2Bkc8inbYbc7GH9d+Dau7ARNUjogp188X548kCdX72FnaQeWlymleqzEiu2QlM2OGpucDO13kjUlEtKb7jfTlgHj4Mp5tvrs819vue6JMWTue9V+AWZPPv76niLvEpuc3PSarXTbHTxxdtht41N2TkfjUuFNL0C/kZA2qu0YwQ7zNJafz5vV+u1bMnS6nQhcsa/phNmOmnADOKOois2yPTWh4vraz0PjfKYNC0Ectt5LD6JJSgfdOTOXaJeD+1+PmAr+SqlulFixHbImsavMfpnl9OvkpNmTkT/H9jJ88gq8evfx9U52rSCueq/tRelBv5JbNOT844dOutpF99mJpa9+F3430u70vGdl270oYJPMAeNtgrLtdbuiJjWn4zGMucpu4Dj3L00nzHZEXCrMfYxtw29r+X0fNsNuDFl9GDY+bZOhxBbmBEUwTVI6qG98FLdOy+GtLcWs3nU43OEopbpT5UGifSWQdSY7S6uI8zjpn9A15b47bMo37QTMD+fD8vuhfI+t1Lp2Piz5BfWuhPZ9ySoYOAW+uQJuXmyHajY8CYhNBtsj71K7qqfwvY73ooQafikMPrfzfw8wajYVSSNbvi5nhp1/s+Q+uzP0+OtO7rHCoJPp2+nt6+cP5YlVu/n1a1t58dvndLw8tlKqZwgWcSPrTAq2VjGkX1x4/7/P+JmtcbLsN/bUyOlh19CbyHPHhC+2nkbEDo1lT4aLfwVH97S/R2T4LFj2a7tc+WSSlO6WPdkWBPxwPsSk2OSqh9EkpRNiPE7uvmg433/+I179+ACXj42gyWdKqa5TtIaAuHCkj6WgdCUTBrZQy+RUEoEvPGg38hOHnWDaZwgkDmD/infJC290PVd8v47NgUkfawut1VVB9pTui+tkOd122fS2V2HsF5vWzukhNEnppLkTs/jb+7v4+aLNjMtOJqtPzyiMo5TqgKK1eOOH4MHNvvIarprYjvLv3c3ptqs6VPiI2IJ0Db7Ozyc5VfIusUvYe1BtlFA6J6WTnA7hoS9PwNcQ4OuPr9VKtEr1Nv4G2L+OisTh7D5UjTEwpG/k7harTrH8uXaPnUg3/nq75D19TLgj6RRNUk7CsP7x/Om6CXxa4uXOp9bjD7Sww6hSqmcq2QL11VQk5lFQGsaVPUqdDIcT+g0PdxSdpknKSTo/tx8///wolnxSwn+/vjXc4SiluorDBWO+yNGkkRSUVQHak6LUqaZJShf4ytmDueHsQTz27i6eXr0n3OEopbpC2iiY+xi+6P4UlFaRlhhFXFSEzz9QqpfRJKWL/OTyUUzN68ePXtrEm5sPhjscpXolEUkWkedE5BMR2SoiZ4tIiogsFpFPg/92+RKcgjIvQzu787FSqtM0SekiLqeDP103gTGZSdz25DqWbisJd0hK9UZ/AN4wxowAzgC2Aj8AlhhjcoElwctdxhhDQWnVyZfDV0p1mCYpXSg+ysXjX5tMXloCty74kJU7ysIdklK9hogkAVOBvwIYY+qMMeXAbODx4M0eB67oysf11sPRmnqdj6JUGGiS0sWSYtwsuHkKg1Jjufnxtawt1NL5SnWRIUApMF9E1ovIX0QkDkgzxhwI3uYgkNaVD3qwKgDoyh6lwkFngXWDlDgPT3x9CtfO+4Ab56/hl1eM5opxmVo+X6mT4wImALcbY1aJyB9oNrRjjDEi0mItABG5BbgFIC0tjWXLlrXrQQsP1QBCacEmlh2M3N91Xq+33c8pnHpKnNBzYu3NcWqS0k36J0Sz8BtT+PbCdXznnxt5af1+fnVlvlamVarzioAiY8yq4OXnsElKsYhkGGMOiEgG0OKEMGPMo8CjAJMmTTLTp09v14M+s+0t3M4G5lwyHZczcpOUZcuW0d7nFE49JU7oObH25jgj939cL5CRFMNzt57Dzz8/ijWFh7n4gRXMf38XDf5AuENTqscxxhwE9opIY2WqGcAWYBFwQ/DYDcDLXfm4B6sCDEqNi+gERaneSntSupnTIdx47hBmjkrjxy9t4hf/2sK85QVcPSmLL07KJjtFe1aU6oDbgYUi4gEKgJuwP7aeEZGbgd3AF7vyAQ9WBcgfpJNmlQoHTVJOkaw+scy/8UyWbC1h4ardPLx0Bw8t3cF5w/ri8fl4Yvda9pfXsP9oDckxbu6bnc/UvA7syqnUacAYswGY1MJVM7rj8Rr8AYqrDV/QSbNKhYUmKaeQiDBzVBozR6Wxv7yGZ9bu5dm1RRz2NjCobzWZyTFMGJTMv3ce4qt/W83VE7P48WWjSIp1hzt0pU5L+8pr8BsYqsuPlQoLTVLCZEByDHfNzOOumXnByURTP7uutt7Pg0s+Zd6KApZvL+W+2aO5aFQ6ToeuDlLqVCootXv2aCE3pcJDk5QIFO128v1ZI/jcmAy+9+xGbn1iHcmxbqbm9uOCEf2YmtuP1PiocIepVK+3M7j78VAd7lEqLDRJiWD5mUksuu08Fm8pZum2EpZtK2HRxv0ADEyJJS8tnry0BPLSEqip97OjxMunJV52FFcS5XZyxbhM5k7M7NCy5ypfA4u3FLNo436cDuHWaTlMHNTlW6Eo1SPsKqsizg19dMhVqbDQJCXCeVwOLhubwWVjMwgEDJv2H2XF9lK2Hqzk0+JKlm0rpSFga1dFux0M6x/PlKGpFFfU8sDb2/n9ku2cm9OXWfnpxLidGOxeJGDnyAjgcECD3/Dup2Us3lJMTb2fzOQYaur9zH1kJVPz+nHnjNwTxukPGHaWeslIiiYhOnIa9LqGAGsKD5MS52FkRmK4w1E9TEFpFemxDi3EqFSYdGuSIiKzsBuCOYG/GGP+u9n1UcA/gInAIeAaY0xhd8bUkzkcwtisZMZmJX92rK4hwO5DVUS7nWQmx+AImbey93A1z68r4tm1Rfz4pU1t3n9SjJsrJ2RyxbhMJg3qQ029nwUf7ObRFQXMfWQluckOllVsZkjfOIb0jaNvfBTr9x7h/R1lrNx5iPLqejwuB9Py+nH52AxmjkwjLsqFMYajNfUcrKjlsLeOmno/tfUBaur9+AMBUuOi6J8YRVpiNKlxnnbXo6it97Oz1MuB8loSY9ykxHlIjfMQ43GyvqSBRc9sYPGWYiprGwAYnpbAFeMz+cK4AWQmx3Tw1W8fYwyrdh3mn2v28v6OMs4b1pfrzhrIhIF9uuWLrrbeT50/QJzHpXOWukFBmZdh8VofRalw6bYkRUScwMPARdhKkWtEZJExZkvIzW4GjhhjhonItcD9wDXdFVNv5HE5yE1LaPG67JRY7pqZxx0X5lJ0pIaAMThECP2uDBhDwNgv16w+sXhcxxrkuCgXt07L4StnDWLBB7t5+v3tPLt2L1V1/iaPk5EUzcyRaUwenMLWgxW89vEBFm8pJsrlID0pmoNHa/E1tK+AnUMg1uMi2u0k1uMkxu0kxmPPx3pcxHqcnw1t7T5URaDFAuhWYnQxF49K55LRaRRX1PLShv3c/8Yn3P/GJwxMiUUEjLGvgcfpILNPDNkpsQxMiWVAcgz1DQEqa+vx+hqo9DUgCFEuB1FuB1EuJx6XA7dDcDsduF0O9h6u5tm1eyk8VE1ClIuzclJ5a0sxL6zfx/C0BL40OZu+CVGUVfoo9fooq6xj975aXjiwHgARqPcHOFpTT3m1Pfka/AxOjSMvPYHhaQkM6RvHvvIaPioqZ+Peo2wrrsQffBFiPU7io1z0T4xibFYy47KTGZ+dzKDUOPYcrmJ7sZdtByspPFRFZnIMYzKTyM9MIqtPzGcJlD9g8NY24Gvw0z8xul3vWW/l9TVQXOHjvLTI6RlU6nTTnT0pk4EdxpgCABF5GrtbaWiSMhv4efD8c8BDIiKmcTxCdQmHQxiY2vmicY3Jygizl2nTplHq9bGrtIqDFbXkZyYxtG9ck16Cn1w2irW7j/Daxwc4VFXHxaNsL0l6UjSpcVE2+fA4iXY5cTqFskofxRW1FFf6KKmopcrnD/a2+Kmua6CmPkC1r4Hy6hqq6xpwOR2MSE/g82cMIC8tnqw+sVTW1nO4qo5D3joqautxHtnDN6+8sEnS9ZWzB7PnUDUvb9jH9hIvDsEOd4ngawhQdKSa1z8+wJHq+uNeg8b7qWsj2Zo8JIU7ZuRyaX4GMR4nVb4G/rVxPwtX7eHn/zr20Xc6hNQ4D+IPUFx/9LMhOKdDSI71kJYYzfC0BDwuBwWlVbz60QGerNnz2d8nxbgZm5XEt0bkkBzrprK2gSpfA15fA0VHavjXhv08uWrPcfGJwICkGF6tOPDZMGFyrJs4j4uKmnoqfbbXaVj/eN7+7rS2Phq9WmGZXdmTHqc9KUqFS3cmKZnA3pDLRcCU1m5jjGkQkaNAKlAWeqPObgzWmzddCgev18vy5cs/u5wE7C1v+iaHmp4INE4D8QOHwXcYfMCRZrf1ANlAtid4oVUCGKDSng5D+eFj8SQBuMAbU8vK91a0eA9jnDAmo4UrMm0kNQ1uDtcY3E6IcQkxLnAFh1ICxtAQgPoA1AcM/gD4DTQEINoFKdE+qNjBqpU7PrvbdODuMbBvSAzGQGKUEO+2yZHXW0t8fOPzalQXPAWlghnuptzn4mCVISVa6B8riNQANfa1dQdP8fb2gRwPB6vc7Cz3U1pjSIsVshIcZMQ58DiFOn8MRZUBCivsyR+oJzYJYl1uYt1Cn6j6Jp/JnvIZ7UpOh3BpfjrZCUfDHYpSp60eMXG2sxuD9eZNl8Khp8QJPSdWjTNyjcxI5JHrJ552yZlSkaQ7+zH3YX8cN8oKHmvxNiLiwv4QPtSNMSmllFKqh+jOJGUNkCsiQ4KbgV2L3a00VOjupVcB7+h8FKWUUkpBNw73BOeY3Aa8iV2C/DdjzGYRuQ9Ya4xZBPwVWCAiO4DD2ERGKaWUUqp756QYY14DXmt27Kch52uBq7szBqWUUkr1TLq2TimllFIRSZMUpZRSSkUkTVKUUkopFZE0SVFKKaVURJKetuJXREqB3e28eV+aVa+NUBpn1+spsfb0OAcZY/qd6mBOlrYjYdVT4oSeE2tPj7PVdqTHJSkdISJrjTGTwh1HWzTOrtdTYtU4I19Pee4aZ9frKbH25jh1uEcppZRSEUmTFKWUUkpFpN6epDwa7gDaSePsej0lVo0z8vWU565xdr2eEmuvjbNXz0lRSimlVM/V23tSlFJKKdVDaZKilFJKqYjUK5MUEZklIttEZIeI/CDc8YQSkb+JSImIbAo5liIii0Xk0+C/fcIZYzCmbBFZKiJbRGSziNwZibGKSLSIrBaRjcE4fxE8PkREVgU/A/8UEU8442wkIk4RWS8irwQvR2qchSLysYhsEJG1wWMR9d53N21HTp62I93jdGpHel2SIiJO4GHgUmAU8CURGRXeqJr4OzCr2bEfAEuMMbnAkuDlcGsA7jbGjALOAv4j+DpGWqw+4EJjzBnAOGCWiJwF3A88YIwZBhwBbg5jjKHuBLaGXI7UOAEuMMaMC6lrEGnvfbfRdqTLaDvSPU6fdsQY06tOwNnAmyGX7wXuDXdczWIcDGwKubwNyAiezwC2hTvGFmJ+GbgokmMFYoF1wBRsVUNXS5+JMMaXFfxPeSHwCiCRGGcwlkKgb7NjEfved8Pz13ake2LWduTk4zut2pFe15MCZAJ7Qy4XBY9FsjRjzIHg+YNAWjiDaU5EBgPjgVVEYKzBrs8NQAmwGNgJlBtjGoI3iZTPwO+B7wOB4OVUIjNOAAO8JSIfisgtwWMR9953I21Hupi2I13mtGpHXN0Zneo4Y4wRkYhZFy4i8cDzwF3GmAoR+ey6SInVGOMHxolIMvAiMCLMIR1HRC4HSowxH4rI9HDH0w7nGWP2iUh/YLGIfBJ6ZaS896plkfb+aDvSNU7HdqQ39qTsA7JDLmcFj0WyYhHJAAj+WxLmeAAQETe2YVlojHkheDgiYwUwxpQDS7Hdncki0piER8Jn4FzgCyJSCDyN7ar9A5EXJwDGmH3Bf0uwDfZkIvi97wbajnQRbUe61GnXjvTGJGUNkBuc7ewBrgUWhTmmtiwCbgievwE7bhtWYn/q/BXYaoz5XchVERWriPQL/vJBRGKw491bsY3MVcGbhT1OY8y9xpgsY8xg7GfyHWPMdURYnAAiEiciCY3ngYuBTUTYe9/NtB3pAtqOdK3Tsh0J98Sabpqs8zlgO3ZM8UfhjqdZbE8BB4B67NjhzdgxxSXAp8DbQEoExHkedjzxI2BD8PS5SIsVGAusD8a5Cfhp8PhQYDWwA3gWiAr3axoS83TglUiNMxjTxuBpc+P/oUh770/B66DtyMnHqe1I98V8WrQjWhZfKaWUUhGpNw73KKWUUqoX0CRFKaWUUhFJkxSllFJKRSRNUpRSSikVkTRJUUoppVRE0iRFdYqI+IM7WzaeumyDMBEZLCG7uyqleh9tQ1R7aFl81Vk1xphx4Q5CKdVjaRui2qQ9KapLiUihiPxWRD4WkdUiMix4fLCIvCMiH4nIEhEZGDyeJiIvisjG4Omc4F05ReQxEdksIm8Fq0AiIneIyJbg/TwdpqeplOom2oaoUJqkqM6KadZVe03IdUeNMWOAh7A7dgL8EXjcGDN9JXh3AAABgUlEQVQWWAg8GDz+ILDcGHMGMAFbmRAgF3jYGDMaKAfmBo//ABgfvJ9bu+vJKaW6nbYhqk1acVZ1ioh4jTHxLRwvBC40xhQENxY7aIxJFZEyIMMYUx88fsAY01dESoEsY4wv5D4GA4uNMbnBy/cAbmPMf4nIG4AXeAl4yRjj7eanqpTqBtqGqPbQnhTVHUwr5zvCF3Lez7H5U5cBD2N/Ma0J2flTKdV7aBuiAE1SVPe4JuTffwfPr8Tu2glwHfBu8PwS4FsAIuIUkaTW7lREHEC2MWYpcA+QBBz3S0wp1eNpG6IAXd2jOi9GRDaEXH7DGNO4hLCPiHyE/SXzpeCx24H5IvKfQClwU/D4ncCjInIz9tfOt7C7u7bECTwRbIQEeNAYU95lz0gpdSppG6LapHNSVJcKjidPMsaUhTsWpVTPo22ICqXDPUoppZSKSNqTopRSSqmIpD0pSimllIpImqQopZRSKiJpkqKUUkqpiKRJilJKKaUikiYpSimllIpI/w9rECQo14JF8AAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 648x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XR71wvkwaXDO","executionInfo":{"status":"ok","timestamp":1618312724070,"user_tz":-120,"elapsed":5661150,"user":{"displayName":"Tianyu Mo","photoUrl":"","userId":"10231734080128882793"}},"outputId":"33aa8cf0-b61c-4255-decf-f44a364845f0"},"source":["pre_l = []\n","for i in pred_labels:\n","  pre_l.extend(i.to(\"cpu\").numpy().tolist())\n","pre_l = np.array(pre_l)\n","\n","print(\"Precision (P):\", metrics.precision_score(true_labels, pre_l))\n","print(\"Recall (R):\", metrics.recall_score(true_labels, pre_l))\n","print(\"F1 score (F):\", metrics.f1_score(true_labels, pre_l))\n","print()\n","print(\"Classification Report\")\n","print(metrics.classification_report(true_labels, pre_l))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Precision (P): 0.5522788203753352\n","Recall (R): 0.662379421221865\n","F1 score (F): 0.6023391812865497\n","\n","Classification Report\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.65      0.69       473\n","           1       0.55      0.66      0.60       311\n","\n","    accuracy                           0.65       784\n","   macro avg       0.65      0.65      0.65       784\n","weighted avg       0.67      0.65      0.66       784\n","\n"],"name":"stdout"}]}]}